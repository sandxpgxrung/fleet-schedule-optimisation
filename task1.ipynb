{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location dataframe\n",
    "location_df = pd.read_csv('SaO_Optilandia_resub_locations.csv')\n",
    "\n",
    "# links dataframe\n",
    "links_df = pd.read_csv('SaO_Optilandia_resub_links.csv')\n",
    "\n",
    "# extract lorry data from json\n",
    "lorry_data = json.load(open('SaO_Optilandia_resub_depot_lorries.json', 'r'))\n",
    "\n",
    "# set count to 0\n",
    "k = 0\n",
    "\n",
    "# initialise lorry list\n",
    "lorry = []\n",
    "\n",
    "# loop -> set i to the respective lorry key\n",
    "for i in lorry_data.keys():\n",
    "    # set j to the the number of lorries at key 'i'\n",
    "    for j in range(0, len(lorry_data[i])):\n",
    "        # append each lorry in lorry_data to lorry list\n",
    "        lorry.append(pd.DataFrame(lorry_data[i][j], index=[k]))\n",
    "        # accumulate index\n",
    "        k += 1\n",
    "\n",
    "# lorry dataframe\n",
    "lorry_df = pd.concat(lorry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 5 rows of lorry_df\n",
    "lorry_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of depot locations (where nodes == depot)\n",
    "depot_locations = np.where(location_df.is_depot)[0]\n",
    "\n",
    "# list of customer locations (where nodes == customers)\n",
    "customer_locations = np.where(location_df.is_customer)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports + visualising the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# parwise distance calculation for each node\n",
    "euclidean = squareform(pdist(location_df[['x', 'y']]))\n",
    "\n",
    "# edges list initialisation\n",
    "edges = []\n",
    "\n",
    "# loop through links_df rows\n",
    "for _, (i, j) in links_df.iterrows():\n",
    "    # append node at i, node at j, and their pairwise distance to edges\n",
    "    edges.append((i, j, euclidean[i, j]))\n",
    "\n",
    "# pos dict intialisation\n",
    "pos = {}\n",
    "\n",
    "# loop through location_df rows\n",
    "for k, v in location_df[['x', 'y']].iterrows():\n",
    "    # update pos dict with array of k, v \n",
    "    pos.update({k:v.values})\n",
    "\n",
    "# initialise depot_labels dict\n",
    "depot_labels = {}\n",
    "\n",
    "# loop throgugh depot_locations\n",
    "for i in depot_locations:\n",
    "    # update depot_labels dict with {i:i}\n",
    "    depot_labels.update({i:i})\n",
    "\n",
    "# initialise customer_labels dict\n",
    "customer_labels = {}\n",
    "\n",
    "# loop through customer_locations\n",
    "for i in customer_locations:\n",
    "    # update customer_labels dict with {i:i}\n",
    "    customer_labels.update({i:i})\n",
    "\n",
    "# initialise nx Graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# feed node list to G\n",
    "G.add_nodes_from(location_df['id'].to_numpy())\n",
    "\n",
    "# feed edges list to G\n",
    "G.add_weighted_edges_from(edges)\n",
    "\n",
    "# resize figure \n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# sketch graph\n",
    "nx.draw(G, pos=pos, node_size=40)\n",
    "\n",
    "# label depot nodes\n",
    "nx.draw_networkx_labels(G, pos, depot_labels)\n",
    "\n",
    "# label customer nodes\n",
    "nx.draw_networkx_labels(G, pos, customer_labels)\n",
    "\n",
    "# mark depot nodes\n",
    "nx.draw_networkx_nodes(G, pos=pos, nodelist=depot_locations, node_color='r', node_size=400, alpha=0.9)\n",
    "\n",
    "# mark customer nodes\n",
    "nx.draw_networkx_nodes(G, pos=pos, nodelist=customer_locations, node_color='g', node_size=200, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clustering nodes (customer_locations) via nearest neighbour sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialise cluster dict\n",
    "cluster = {124:[], 127:[], 167:[], 523:[]}\n",
    "\n",
    "# intialise nodes list\n",
    "nodes = [] \n",
    "\n",
    "# loop through each node in customer_locations\n",
    "for node in customer_locations:\n",
    "    # check if node in nodes\n",
    "    if node not in nodes:\n",
    "        # initialise dist list\n",
    "        dist = []\n",
    "        # loop through each depot key\n",
    "        for depot in cluster.keys():\n",
    "            # append euclidean weights to dist \n",
    "            dist.append(euclidean[node, depot])\n",
    "        # get shortest distance\n",
    "        shortestDist = min(dist)\n",
    "        # match shortest distance to equivalent node index\n",
    "        nearestDepotIndex = np.where(euclidean[node]==shortestDist)\n",
    "        # add node to relative nearest depot location\n",
    "        cluster[int(nearestDepotIndex[0])].append(node)\n",
    "        # track applied nodes\n",
    "        nodes.append(node)\n",
    "        # clear dist\n",
    "        dist.clear()\n",
    "\n",
    "# print allocated nodes to relative cluster points (depot locations)\n",
    "print(cluster)\n",
    "\n",
    "# clear nodes list\n",
    "nodes.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "states and constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting required column \n",
    "location_df['required'] = location_df['capacity']-location_df['level']\n",
    "\n",
    "# displaying rows where is_customer true\n",
    "location_df[location_df['is_customer']==True].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: finding next nearest customer node\n",
    "def nearest_customer(currentState, customerList):\n",
    "    #initialise dist dict\n",
    "    dist = {}\n",
    "    \n",
    "    # loop through customerList\n",
    "    for i in customerList:\n",
    "        # check for all where customer != currentState\n",
    "        if i != currentState:\n",
    "            # update dist with available customer index and their relative weights\n",
    "            dist.update({i:euclidean[i,currentState]})\n",
    "\n",
    "    # initialise temp list\n",
    "    temp = []\n",
    "\n",
    "    # loop through keys of dist \n",
    "    for i in dist.keys():\n",
    "        # add weights to temp\n",
    "        temp.append(dist[i])\n",
    "    \n",
    "    # get lowest weight\n",
    "    _shortestDist = min(temp)\n",
    "    \n",
    "    # find relative index of lowest weight\n",
    "    nearestCustomerIndex = np.where(euclidean[currentState]==_shortestDist)\n",
    "    \n",
    "    # return next index with relative weight\n",
    "    return int(nearestCustomerIndex[0]), _shortestDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test nearest_customer()\n",
    "nearest_customer(1, [2, 3, 1, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: finding the nearest depot\n",
    "def nearest_depot(currentState, depotList):\n",
    "    # intialise dist dict\n",
    "    dist = {}\n",
    "\n",
    "    # loop through depotList\n",
    "    for i in depotList:\n",
    "        # update dist with depot and their relative distance values\n",
    "        dist.update({i:euclidean[currentState, i]})\n",
    "    \n",
    "    # intialise temp list\n",
    "    temp = []\n",
    "\n",
    "    # loop through dist.keys()\n",
    "    for i in dist.keys():\n",
    "        # add values of each dist.keys() to temp \n",
    "        temp.append(dist[i])\n",
    "\n",
    "    # get lowest depot weight\n",
    "    _shortestDist = min(temp)\n",
    "\n",
    "    # get the relative node index of the closest depot\n",
    "    _nearestDepotIndex = np.where(euclidean[currentState]==_shortestDist)\n",
    "\n",
    "    # return next depot index with relative weight\n",
    "    return int(_nearestDepotIndex[0]), _shortestDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test near_depot()\n",
    "nearest_depot(1, depot_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in lorry_df.iterrows():\n",
    "lorry_df['depot'] = lorry_df.lorry_id.apply(lambda x: x.split('-')[0])\n",
    "lorry_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "greedy search (breadth-first-search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialise routes dict\n",
    "routes = {}\n",
    "\n",
    "# loop through lorry_df.index \n",
    "for i in lorry_df.index:\n",
    "    # update routes with key: lorry_id, value: capacity\n",
    "    routes.update({lorry_df['lorry_id'][i]:[(lorry_df.depot[i]),lorry_df['capacity'][i]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display journeys so far\n",
    "routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routing from A to B using recursive Breadth-First-Search based algorithm to find shortest route, with back tracing\n",
    "def routing(currState, toState, edges):\n",
    "    # intialise visitedState list for tracking node traversal\n",
    "    visitedState = [currState]\n",
    "    # initialise visitedEdge list for tracking edge traversal\n",
    "    visitedEdge = []\n",
    "    # intialise edgeMemory list for storing the explored edges\n",
    "    edgeMemory = []\n",
    "    # intialise queue list for choosing the central node for next traversal\n",
    "    queue = [currState]\n",
    "\n",
    "    # loop while toState is not found\n",
    "    while currState != toState:\n",
    "        # remove and store the last element of the queue list as q\n",
    "        q = queue.pop(0)\n",
    "        \n",
    "        # intialise currEdges dict which holds the next set of edges for traversals\n",
    "        currEdges = {}\n",
    "        # get the nodes at each edge, where either nodes are equivalent to q\n",
    "        for edge in list(np.where(links_df[['id1', 'id2']]==q)[0]):\n",
    "            # update the dict with the relative edge key and the node pairs\n",
    "            currEdges.update({edge:[edges[edge][0], edges[edge][1]]})\n",
    "        \n",
    "        # store the explored edges in edgeMemory list\n",
    "        edgeMemory.append(currEdges)\n",
    "\n",
    "        # loop through each edge in currEdges\n",
    "        for edge in currEdges:\n",
    "            # check if the edge has been visited \n",
    "            if edge not in visitedEdge:\n",
    "                # if not visited then add the edge to visitedEdge\n",
    "                visitedEdge.append(edge)\n",
    "                # check the node index in the edge that has not been visited \n",
    "                if currEdges[edge][0] not in visitedState and currEdges[edge][1] in visitedState:\n",
    "                    # set currState to the unvisited node \n",
    "                    currState = currEdges[edge][0]\n",
    "                    # mark the node in currState as visited \n",
    "                    visitedState.append(currState)\n",
    "                    # add new currState to queue \n",
    "                    queue.append(currState)\n",
    "                    # check if toState reached\n",
    "                    if currState == toState:\n",
    "                        # set currState to toState\n",
    "                        currState = toState\n",
    "                        # end loop\n",
    "                        break \n",
    "                # similar to above but in the context of different index position of the node that has not been visited\n",
    "                if currEdges[edge][1] not in visitedState and edges[edge][0] in visitedState:\n",
    "                    currState = currEdges[edge][1]\n",
    "                    visitedState.append(currState)\n",
    "                    queue.append(currState)\n",
    "                    if currState == toState:\n",
    "                        currState = toState\n",
    "                        break\n",
    "    \n",
    "    # set startState as the first node in visitedState list\n",
    "    startState = visitedState[0]\n",
    "    # set lastQ as the toState for tracking q node from end of order\n",
    "    lastQ = [toState]\n",
    "    # intialise backtrace list for backtracing the edges from edgeMemory\n",
    "    backtrace = []\n",
    "    # initialise nodetrace list for backtracing the nodes from edgeMemory\n",
    "    nodetrace = []\n",
    "\n",
    "    # intialise edgeMemoryReversed for reordering edgeMemory \n",
    "    edgeMemoryReversed = []\n",
    "    # loop through each index between range 0 and length of edgeMemory\n",
    "    for i in range (0, len(edgeMemory)):\n",
    "        # set endElement to the last element in edgeMemory\n",
    "        endElement = edgeMemory.pop(-1)\n",
    "        # add the endElement to edgeMemoryReversed\n",
    "        edgeMemoryReversed.append(endElement)\n",
    "    \n",
    "    # while last element in lastQ is not equivalent to the startState\n",
    "    while lastQ[-1] != startState:\n",
    "        # loop through each edge options in edgeMemoryReversed\n",
    "        for edgeOpt in edgeMemoryReversed:\n",
    "            # loop through each edge from as keys of the edge options\n",
    "            for edge in edgeOpt.keys():\n",
    "\n",
    "                # check if last element of lastQ is in the set of edge options given the edge\n",
    "                if lastQ[-1] in edgeOpt[edge]:\n",
    "                    # add the edge to backtrace \n",
    "                    backtrace.append(edge)\n",
    "                    # check index of node which matches the lastQ element \n",
    "                    if lastQ[-1] == edgeOpt[edge][0] and lastQ[-1] != edgeOpt[edge][1]:\n",
    "                        # update lastQ as the the node which does not match the lastQ element\n",
    "                        lastQ.append(edgeOpt[edge][1])\n",
    "                        # add the node to nodetrace\n",
    "                        nodetrace.append(edgeOpt[edge][1])\n",
    "                        # return to while iterate\n",
    "                        break\n",
    "                        # similar to above but in the context of different index postion of the matching node with lastQ element\n",
    "                    if lastQ[-1] != edgeOpt[edge][0] and lastQ[-1] == edgeOpt[edge][1]:\n",
    "                        lastQ.append(edgeOpt[edge][0])\n",
    "                        nodetrace.append(edgeOpt[edge][0])\n",
    "                        break\n",
    "    \n",
    "    # re-ordering edges from start to end\n",
    "    edgeTraversed = []\n",
    "    for i in range(0, len(backtrace)):\n",
    "        endElement = backtrace.pop(-1)\n",
    "        edgeTraversed.append(endElement)\n",
    "\n",
    "    # re-ordering nodes from start to end \n",
    "    nodeOrder = []\n",
    "    for i in range(0, len(nodetrace)):\n",
    "        endElement = nodetrace.pop(-1)\n",
    "        nodeOrder.append(endElement)\n",
    "    \n",
    "    routeWeight = []\n",
    "    for edge in edgeTraversed:\n",
    "        routeWeight.append(edges[edge][2])\n",
    "\n",
    "    # return the the order in which nodes were visited and the order in which edges were traversed\n",
    "    return nodeOrder, edgeTraversed, routeWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: gives the node order in routing\n",
    "print(f'node order: {routing(124, 10, edges)[0]}')\n",
    "# test: gives the traversed edges in routing\n",
    "print(f'edge order: {routing(124, 10, edges)[1]}')\n",
    "# test: gives the weight routes for traversed\n",
    "print(f'route weight: {routing(124, 10, edges)[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(routes)\n",
    "# temp variable initialisation for testing\n",
    "tempRoutes = {'124-0': [['124', 8]], '124-1': [['124', 8]], '124-2': [['124', 16]], '124-3': [['124', 25]], '127-0': [['127', 8]], '127-1': [['127', 16]], '127-2': [['127', 25]], '167-0': [['167', 8]], '167-1': [['167', 16]], '167-2': [['167', 16]], '167-3': [['167', 25]], '523-0': [['523', 8]], '523-1': [['523', 16]], '523-2': [['523', 25]]}\n",
    "tempCluster = {124: [10, 15, 37, 43, 71, 87, 129, 130, 140, 149, 170, 196, 209, 210, 252, 254, 263, 264, 266, 278, 281, 288, 297, 321, 327, 336, 369, 418, 461, 470, 476, 492, 503, 542, 561, 566, 572, 606, 616, 626, 627, 633], 127: [26, 77, 96, 126, 151, 178, 198, 215, 269, 279, 302, 357, 387, 416, 471, 515, 532, 534, 562, 583, 586, 609], 167: [20, 22, 25, 64, 72, 75, 86, 141, 144, 155, 166, 190, 193, 243, 282, 313, 316, 319, 348, 356, 381, 390, 393, 398, 431, 454, 466, 468, 469, 478, 485, 489, 513, 514, 548, 569, 580, 595, 615, 621], 523: [7, 152, 176, 235, 253, 276, 332, 338, 367, 401, 456, 490, 497, 508, 564, 588, 630]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialise totalRouteCost list to store route costs\n",
    "routeTotalCost = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(lorryId, allocatedCustomers):\n",
    "    currentId = lorryId\n",
    "    operatingDepot = currentId.split('-')[0]\n",
    "    currentCapacity = float(lorry_df[lorry_df['lorry_id']==currentId].capacity)\n",
    "    currentCpm = float(lorry_df[lorry_df['lorry_id']==currentId].cpm)\n",
    "    currentCptm = float(lorry_df[lorry_df['lorry_id']==currentId].cptm)\n",
    "    currentState = int(lorry_df[lorry_df['lorry_id']==currentId].depot)\n",
    "    currentDepot = int(lorry_df[lorry_df['lorry_id']==currentId].depot)\n",
    "    nextCustomerCapacity = 0\n",
    "\n",
    "    while (currentCapacity >= nextCustomerCapacity) and (len(allocatedCustomers)>0):\n",
    "        nextCustomer = nearest_customer(currentState, allocatedCustomers)\n",
    "        nextCustomerCapacity = location_df[location_df['id']==nextCustomer[0]]['capacity'].iloc[0]\n",
    "        nextCustomerRequired = location_df[location_df['id']==nextCustomer[0]]['required'].iloc[0]\n",
    "        nextCustomerTankSpace = nextCustomerCapacity-nextCustomerRequired\n",
    "\n",
    "        # check if customer tank space is less than 50% \n",
    "        if nextCustomerTankSpace < (nextCustomerCapacity/2):\n",
    "            #routes[currentId].append([int(nextCustomer[0]), -nextCustomerRequired])\n",
    "            tempRoutes[currentId].append([int(nextCustomer[0]), -nextCustomerRequired])\n",
    "            routeCost = round(sum(routing(currentState, nextCustomer[0], edges)[2])*(currentCpm+(currentCapacity*currentCptm)), 2)\n",
    "            routeTotalCost.append(routeCost)\n",
    "            currentCapacity = currentCapacity-nextCustomerRequired\n",
    "            allocatedCustomers.remove(nextCustomer[0])\n",
    "            currentState = nextCustomer[0]\n",
    "\n",
    "        # check if customer tank space is more than 50%\n",
    "        elif nextCustomerTankSpace > (nextCustomerCapacity/2):\n",
    "            # currentState = nextCustomer[0]\n",
    "            tempRoutes[currentId].append([int(nextCustomer[0]), -0])\n",
    "            routeCost = round(sum(routing(currentState, nextCustomer[0], edges)[2])*(currentCpm+(currentCapacity*currentCptm)), 2)\n",
    "            routeTotalCost.append(routeCost)\n",
    "            currentCapacity = currentCapacity-0\n",
    "            # if tank space is less than 50% then remove customer node as they do not require filling\n",
    "            allocatedCustomers.remove(nextCustomer[0])\n",
    "            currentState = nextCustomer[0]\n",
    "\n",
    "        if len(allocatedCustomers) != 0:\n",
    "            nextCustomerCapacity = location_df[location_df['id']==(nearest_customer(nextCustomer[0], allocatedCustomers)[0])]['required'].iloc[0]\n",
    "    \n",
    "    if currentCapacity < nextCustomerCapacity:\n",
    "        tempCluster[currentDepot]=allocatedCustomers\n",
    "        print(f'{currentId} finished operating at {currentState}')\n",
    "    \n",
    "    elif len(allocatedCustomers)==0:\n",
    "        print(f'{currentId} finished operating at {currentState}')\n",
    "\n",
    "# route(\"124-0\", tempCluster[124])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for depot in cluster.keys():\n",
    "#for depot in tempCluster.keys():\n",
    "for i in depot_locations:\n",
    "    #df = lorry_df[lorry_df['depot']==depot].sort_values(by=['capacity'])\n",
    "    #df = lorry_df[lorry_df['depot']==i]\n",
    "    df = lorry_df[lorry_df['depot']==f'{i}']\n",
    "    #print(f'{df}\\n')\n",
    "    count = 0 \n",
    "\n",
    "    for j in df.index:\n",
    "        print(f'{df.loc[j].lorry_id} started operating')\n",
    "        #route(df.loc[j].lorry_id, cluster[depot])\n",
    "        #route(df.loc[j].lorry_id, tempCluster[depot])\n",
    "        route(df.loc[j].lorry_id, tempCluster[i])\n",
    "        count += 1\n",
    "        \n",
    "        #if len(cluster[depot])!=0 and count==len(df.index): \n",
    "        if len(tempCluster[i])!=0 and count==(len(df.index)):\n",
    "            print(f'if statement reached')\n",
    "            #while len(cluster[depot]!=0):\n",
    "            while len(tempCluster[i]!=0):\n",
    "                print(f'while statement reached')\n",
    "                currentId = lorry_df.loc[j]['lorry_id']\n",
    "                currentState = routes[currentId][-1][0]\n",
    "                nearDepot = nearest_depot(currentState)\n",
    "                print(f'{currentId} is refilling tank at {nearDepot[0]}')\n",
    "                routeCost = round(sum(routing(currentState, nearDepot[0], edges)[2])*((lorry_df.loc[j]['cpm'])+(lorry_df.loc[j]['capacity']*lorry_df.loc[j]['cptm'])), 2)\n",
    "                routeTotalCost.append(routeCost)\n",
    "                #routes[currentId].append([int(nearDepot[0]),int(lorry_df.loc[j]['capacity'])])\n",
    "                tempRoutes[currentId].append([int(nearDepot[0]),int(lorry_df.loc[j]['capacity'])])\n",
    "                currentState = nearDepot[0]\n",
    "                #route(currentId, cluster[depot])\n",
    "                route(currentId, tempCluster[i])\n",
    "        #elif len(cluster[depot])==0:\n",
    "        elif len(tempCluster[i])==0:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'tempRoutes: {tempRoutes} \\n')\n",
    "#print(f'tempCluster: {tempCluster}')\n",
    "#print(lorry_df)\n",
    "for i in tempRoutes.keys():\n",
    "    print(i)\n",
    "    print(f'{tempRoutes[i]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in depot_locations:\n",
    "    print(i)\n",
    "    df = lorry_df[lorry_df['depot']==f'{i}']\n",
    "    print(df)\n",
    "    print(f'\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6dc963290d6e8c477cd46c162738e9c07bc42d08c69d19efe0ecb8c0835c38d0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
