{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location dataframe\n",
    "location_df = pd.read_csv('SaO_Optilandia_resub_locations.csv')\n",
    "\n",
    "# links dataframe\n",
    "links_df = pd.read_csv('SaO_Optilandia_resub_links.csv')\n",
    "\n",
    "# extract lorry data from json\n",
    "lorry_data = json.load(open('SaO_Optilandia_resub_depot_lorries.json', 'r'))\n",
    "\n",
    "# set count to 0\n",
    "k = 0\n",
    "\n",
    "# initialise lorry list\n",
    "lorry = []\n",
    "\n",
    "# loop -> set i to the respective lorry key\n",
    "for i in lorry_data.keys():\n",
    "    # set j to the the number of lorries at key 'i'\n",
    "    for j in range(0, len(lorry_data[i])):\n",
    "        # append each lorry in lorry_data to lorry list\n",
    "        lorry.append(pd.DataFrame(lorry_data[i][j], index=[k]))\n",
    "        # accumulate index\n",
    "        k += 1\n",
    "\n",
    "# lorry dataframe\n",
    "lorry_df = pd.concat(lorry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting required column \n",
    "location_df['required'] = location_df['capacity']-location_df['level']\n",
    "\n",
    "# displaying rows where is_customer true\n",
    "location_df[location_df['is_customer']==True].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 'depot' column to lorry_df and updae with the lorry's relative depot \n",
    "lorry_df['depot'] = lorry_df.lorry_id.apply(lambda x: x.split('-')[0])\n",
    "lorry_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of depot locations (where nodes == depot)\n",
    "depot_locations = np.where(location_df.is_depot)[0]\n",
    "\n",
    "# list of customer locations (where nodes == customers)\n",
    "customer_locations = np.where(location_df.is_customer)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports + visualising the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# parwise distance calculation for each node\n",
    "euclidean = squareform(pdist(location_df[['x', 'y']]))\n",
    "\n",
    "# edges list initialisation\n",
    "edges = []\n",
    "\n",
    "# loop through links_df rows\n",
    "for _, (i, j) in links_df.iterrows():\n",
    "    # append node at i, node at j, and their pairwise distance to edges\n",
    "    edges.append((i, j, euclidean[i, j]))\n",
    "\n",
    "# pos dict intialisation\n",
    "pos = {}\n",
    "\n",
    "# loop through location_df rows\n",
    "for k, v in location_df[['x', 'y']].iterrows():\n",
    "    # update pos dict with array of k, v \n",
    "    pos.update({k:v.values})\n",
    "\n",
    "# initialise depot_labels dict\n",
    "depot_labels = {}\n",
    "\n",
    "# loop throgugh depot_locations\n",
    "for i in depot_locations:\n",
    "    # update depot_labels dict with {i:i}\n",
    "    depot_labels.update({i:i})\n",
    "\n",
    "# initialise customer_labels dict\n",
    "customer_labels = {}\n",
    "\n",
    "# loop through customer_locations\n",
    "for i in customer_locations:\n",
    "    # update customer_labels dict with {i:i}\n",
    "    customer_labels.update({i:i})\n",
    "\n",
    "# initialise nx Graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# feed node list to G\n",
    "G.add_nodes_from(location_df['id'].to_numpy())\n",
    "\n",
    "# feed edges list to G\n",
    "G.add_weighted_edges_from(edges)\n",
    "\n",
    "# resize figure \n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# sketch graph\n",
    "nx.draw(G, pos=pos, node_size=40)\n",
    "\n",
    "# label depot nodes\n",
    "nx.draw_networkx_labels(G, pos, depot_labels)\n",
    "\n",
    "# label customer nodes\n",
    "nx.draw_networkx_labels(G, pos, customer_labels)\n",
    "\n",
    "# mark depot nodes\n",
    "nx.draw_networkx_nodes(G, pos=pos, nodelist=depot_locations, node_color='r', node_size=400, alpha=0.9)\n",
    "\n",
    "# mark customer nodes\n",
    "nx.draw_networkx_nodes(G, pos=pos, nodelist=customer_locations, node_color='g', node_size=200, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clustering nodes ... (nearest-neighbour approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialise cluster dict\n",
    "cluster = {124:[], 127:[], 167:[], 523:[]}\n",
    "\n",
    "# intialise nodes list\n",
    "nodes = [] \n",
    "\n",
    "# loop through each node in customer_locations\n",
    "for node in customer_locations:\n",
    "    # check if node in nodes\n",
    "    if node not in nodes:\n",
    "        # initialise dist list\n",
    "        dist = []\n",
    "        # loop through each depot key\n",
    "        for depot in cluster.keys():\n",
    "            # append euclidean weights to dist \n",
    "            dist.append(euclidean[node, depot])\n",
    "        # get shortest distance\n",
    "        shortestDist = min(dist)\n",
    "        # match shortest distance to equivalent node index\n",
    "        nearestDepotIndex = np.where(euclidean[node]==shortestDist)\n",
    "        # add node to relative nearest depot location\n",
    "        cluster[int(nearestDepotIndex[0])].append(node)\n",
    "        # track applied nodes\n",
    "        nodes.append(node)\n",
    "        # clear dist\n",
    "        dist.clear()\n",
    "\n",
    "# print allocated nodes to relative cluster points (depot locations)\n",
    "print(cluster)\n",
    "\n",
    "# clear nodes list\n",
    "nodes.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(breadth-first-search used for pathfinding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routing from A to B using recursive Breadth-First-Search based algorithm (pathfinding)\n",
    "def routing(currState, toState, edges):\n",
    "    # intialise visitedState list for tracking node traversal\n",
    "    visitedState = [currState]\n",
    "    # initialise visitedEdge list for tracking edge traversal\n",
    "    visitedEdge = []\n",
    "    # intialise edgeMemory list for storing the explored edges\n",
    "    edgeMemory = []\n",
    "    # intialise queue list for choosing the central node for next traversal\n",
    "    queue = [currState]\n",
    "\n",
    "    # loop while toState is not found\n",
    "    while currState != toState:\n",
    "        # remove and store the last element of the queue list as q\n",
    "        q = queue.pop(0)\n",
    "        \n",
    "        # intialise currEdges dict which holds the next set of edges for traversals\n",
    "        currEdges = {}\n",
    "        # get the nodes at each edge, where either nodes are equivalent to q\n",
    "        for edge in list(np.where(links_df[['id1', 'id2']]==q)[0]):\n",
    "            # update the dict with the relative edge key and the node pairs\n",
    "            currEdges.update({edge:[edges[edge][0], edges[edge][1]]})\n",
    "        \n",
    "        # store the explored edges in edgeMemory list\n",
    "        edgeMemory.append(currEdges)\n",
    "\n",
    "        # loop through each edge in currEdges\n",
    "        for edge in currEdges:\n",
    "            # check if the edge has been visited \n",
    "            if edge not in visitedEdge:\n",
    "                # if not visited then add the edge to visitedEdge\n",
    "                visitedEdge.append(edge)\n",
    "                # check the node index in the edge that has not been visited \n",
    "                if currEdges[edge][0] not in visitedState and currEdges[edge][1] in visitedState:\n",
    "                    # set currState to the unvisited node \n",
    "                    currState = currEdges[edge][0]\n",
    "                    # mark the node in currState as visited \n",
    "                    visitedState.append(currState)\n",
    "                    # add new currState to queue \n",
    "                    queue.append(currState)\n",
    "                    # check if toState reached\n",
    "                    if currState == toState:\n",
    "                        # set currState to toState\n",
    "                        currState = toState\n",
    "                        # end loop\n",
    "                        break \n",
    "                # similar to above but in the context of different index position of the node that has not been visited\n",
    "                if currEdges[edge][1] not in visitedState and edges[edge][0] in visitedState:\n",
    "                    currState = currEdges[edge][1]\n",
    "                    visitedState.append(currState)\n",
    "                    queue.append(currState)\n",
    "                    if currState == toState:\n",
    "                        currState = toState\n",
    "                        break\n",
    "    \n",
    "    # set startState as the first node in visitedState list\n",
    "    startState = visitedState[0]\n",
    "    # set lastQ as the toState for tracking q node from end of order\n",
    "    lastQ = [toState]\n",
    "    # intialise backtrace list for backtracing the edges from edgeMemory\n",
    "    backtrace = []\n",
    "    # initialise nodetrace list for backtracing the nodes from edgeMemory\n",
    "    nodetrace = []\n",
    "\n",
    "    # intialise edgeMemoryReversed for reordering edgeMemory \n",
    "    edgeMemoryReversed = []\n",
    "    # loop through each index between range 0 and length of edgeMemory\n",
    "    for i in range (0, len(edgeMemory)):\n",
    "        # set endElement to the last element in edgeMemory\n",
    "        endElement = edgeMemory.pop(-1)\n",
    "        # add the endElement to edgeMemoryReversed\n",
    "        edgeMemoryReversed.append(endElement)\n",
    "    \n",
    "    # while last element in lastQ is not equivalent to the startState\n",
    "    while lastQ[-1] != startState:\n",
    "        # loop through each edge options in edgeMemoryReversed\n",
    "        for edgeOpt in edgeMemoryReversed:\n",
    "            # loop through each edge from as keys of the edge options\n",
    "            for edge in edgeOpt.keys():\n",
    "\n",
    "                # check if last element of lastQ is in the set of edge options given the edge\n",
    "                if lastQ[-1] in edgeOpt[edge]:\n",
    "                    # add the edge to backtrace \n",
    "                    backtrace.append(edge)\n",
    "                    # check index of node which matches the lastQ element \n",
    "                    if lastQ[-1] == edgeOpt[edge][0] and lastQ[-1] != edgeOpt[edge][1]:\n",
    "                        # update lastQ as the the node which does not match the lastQ element\n",
    "                        lastQ.append(edgeOpt[edge][1])\n",
    "                        # add the node to nodetrace\n",
    "                        nodetrace.append(edgeOpt[edge][1])\n",
    "                        # return to while iterate\n",
    "                        break\n",
    "                        # similar to above but in the context of different index postion of the matching node with lastQ element\n",
    "                    if lastQ[-1] != edgeOpt[edge][0] and lastQ[-1] == edgeOpt[edge][1]:\n",
    "                        lastQ.append(edgeOpt[edge][0])\n",
    "                        nodetrace.append(edgeOpt[edge][0])\n",
    "                        break\n",
    "    \n",
    "    # re-ordering edges from start to end\n",
    "    edgeTraversed = []\n",
    "    for i in range(0, len(backtrace)):\n",
    "        endElement = backtrace.pop(-1)\n",
    "        edgeTraversed.append(endElement)\n",
    "\n",
    "    # re-ordering nodes from start to end \n",
    "    nodeOrder = []\n",
    "    for i in range(0, len(nodetrace)):\n",
    "        endElement = nodetrace.pop(-1)\n",
    "        nodeOrder.append(endElement)\n",
    "    \n",
    "    # adding route weight (distance between nodes) to each traversal made\n",
    "    routeWeight = []\n",
    "    for edge in edgeTraversed:\n",
    "        routeWeight.append(edges[edge][2])\n",
    "\n",
    "    # return the the order in which nodes were visited and the order in which edges were traversed\n",
    "    return nodeOrder, edgeTraversed, routeWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: gives the node order in routing\n",
    "print(f'node order: {routing(124, 10, edges)[0]}')\n",
    "# test: gives the traversed edges in routing\n",
    "print(f'edge order: {routing(124, 10, edges)[1]}')\n",
    "# test: gives the weight routes for traversed\n",
    "print(f'weights: {routing(124, 10, edges)[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign next element in list as customer (no need for distance calc. here since it is considered in Genetic Algorithm) \n",
    "def next_customer(customerList):\n",
    "    # check if customerList is not empty\n",
    "    if len(customerList)!=0:\n",
    "        # set nextCustomer to the next element in the list\n",
    "        nextCustomer=customerList[0]\n",
    "    # return the next customer\n",
    "    return nextCustomer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test\n",
    "next_customer([5, 3, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: finding the nearest depot (nearest_depot included incase lorry fuel refill is required)\n",
    "def nearest_depot(currentState, depotList):\n",
    "    # intialise dist dict\n",
    "    dist = {}\n",
    "\n",
    "    # loop through depotList\n",
    "    for i in depotList:\n",
    "        # update dist with depot and their relative distance values\n",
    "        dist.update({i:euclidean[currentState, i]})\n",
    "    \n",
    "    # intialise temp list\n",
    "    temp = []\n",
    "\n",
    "    # loop through dist.keys()\n",
    "    for i in dist.keys():\n",
    "        # add values of each dist.keys() to temp \n",
    "        temp.append(dist[i])\n",
    "\n",
    "    # get lowest depot weight\n",
    "    _shortestDist = min(temp)\n",
    "\n",
    "    # get the relative node index of the closest depot\n",
    "    _nearestDepotIndex = np.where(euclidean[currentState]==_shortestDist)\n",
    "\n",
    "    # return next depot index with relative weight\n",
    "    return int(_nearestDepotIndex[0]), _shortestDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test near_depot()\n",
    "nearest_depot(1, depot_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "genetic algorithm for exploring solution set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import random\n",
    "\n",
    "# function to generate a random path order (consider as genome) for each depot # returns a dict \n",
    "def randomPathArrangement(cluster):\n",
    "    randomPathArr = {}\n",
    "    customerAllocation = cluster\n",
    "    for depot in depot_locations:\n",
    "        # append depot as key and list of randomly arranged customer nodes to randomPathArr\n",
    "        randomPathArr.update({depot:random.sample(customerAllocation[depot], len(customerAllocation[depot]))})\n",
    "    return randomPathArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate multiple initial solutions (population) # returns genomes (individual solution) in a list\n",
    "def population_init(cluster, size):\n",
    "    population = []\n",
    "    for i in range(0, size):\n",
    "        population.append(randomPathArrangement(cluster))\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return populationFitness at each index...\n",
    "def fitness(population, edges):\n",
    "\n",
    "    # to store each weight per traversal made between two nodes (when calculating traversal distance per depot)\n",
    "    genomeWeight = []\n",
    "\n",
    "    # for a possible solution in the set of solutions (genome in population)\n",
    "    for genome in population:\n",
    "        # initialise genomeFitness dict to store distances at each depot per genome \n",
    "        genomeFitness = {}\n",
    "        for depot in genome.keys():\n",
    "        #for depot in depot_locations:\n",
    "            genomeFitness.update({depot:[]})\n",
    "            nodes = genome[depot]\n",
    "            # loop for length of nodes\n",
    "            for idx in range(len(nodes)-1):\n",
    "                # set nodeA to current loop index\n",
    "                nodeA = nodes[idx]\n",
    "                # set nodeB to next loop index\n",
    "                nodeB = nodes[idx+1]\n",
    "                # get sum of each traversal distance occurence between two nodes | routing() enables this \n",
    "                distance = sum(routing(nodeA, nodeB, edges)[2])\n",
    "                genomeFitness[depot].append(distance)\n",
    "        # update popFitness list with each genome and relative fitness values\n",
    "        genomeWeight.append(genomeFitness)\n",
    "\n",
    "    genomeWeights = []\n",
    "    for genome in genomeWeight:\n",
    "        # initialise popWeight list to store total weight at each depot for genome\n",
    "        depotWeight = []\n",
    "        # loop through each depot (chromosome per genome)\n",
    "        for depot in genome:\n",
    "            depotWeight.append({depot:sum(genome[depot])})\n",
    "        genomeWeights.append(depotWeight)\n",
    "    \n",
    "    # to store the weight per index (weight per genome) [each solution indicated by index i.e., 0, 1, 2 etc.]\n",
    "    weightIndex = {}\n",
    "    for idx, genome in enumerate(genomeWeights):\n",
    "        tempIndexStore = []\n",
    "        for depot in genome:\n",
    "            for i in depot.values():\n",
    "                tempIndexStore.append(i)\n",
    "        weightIndex.update({idx:sum(tempIndexStore)})\n",
    "    \n",
    "    return population, weightIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection() uses weighted selection probability for returning 2 cluster arrangement (2 genomes)\n",
    "def selection(population, popWeights):\n",
    "    # selectionPair defines a list containing # of genomes selected through concept of roulette-wheel (in this case k=2). \n",
    "    selectionPair = random.choices(population=population, weights=popWeights, k=2)\n",
    "    # return the selectionPair (in form list)\n",
    "    return selectionPair "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossover() takes two routes (genomes) and performs crossover operation to produce new routes (offspring)\n",
    "def crossover(selectionPair):\n",
    "    # initialise routeA (i.e., genome 1)\n",
    "    routeA = selectionPair[0]\n",
    "    # initialise routeB (i.e., genome 2)\n",
    "    routeB = selectionPair[1]\n",
    "    \n",
    "    # check if both routes (both genomes) have same number of keys (depots)\n",
    "    if len(routeA.keys()) != len(routeB.keys()):\n",
    "        # give error warning\n",
    "        print(f'#---crossover error---# route depots are not of same length')\n",
    "    # if route keys are of same length then proceed with crossover\n",
    "    else:\n",
    "        # set random crossover point nPoint\n",
    "        nPoint = random.randint(1, len(routeA.keys())-1)\n",
    "        # get routeA.values() up to nPoint \n",
    "        extractRouteA1 = list(routeA.values())[nPoint:]\n",
    "        # get routeB.values() up to nPoint\n",
    "        extractRouteB1 = list(routeB.values())[nPoint:]\n",
    "        # get routeA.values() beyond nPoint\n",
    "        extractRouteA2 = list(routeA.values())[:nPoint]\n",
    "        # get routeB.values() beyond nPoint\n",
    "        extractRouteB2 = list(routeB.values())[:nPoint]\n",
    "\n",
    "        # set offsprings as corresponding concantenation of each route extracts\n",
    "        offspringA = extractRouteB2+extractRouteA1\n",
    "        offspringB = extractRouteA2+extractRouteB1\n",
    "\n",
    "        # intialise offspring dicts\n",
    "        newRouteA = {}\n",
    "        newRouteB = {}\n",
    "\n",
    "        # loop through each depot nodes\n",
    "        for i, depot in enumerate(depot_locations):\n",
    "            # allocate new routes to relative depots\n",
    "            newRouteA.update({depot:offspringA[i]})\n",
    "            newRouteB.update({depot:offspringB[i]})\n",
    "\n",
    "    # return the new offsprings\n",
    "    return newRouteA, newRouteB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutation() selects a random depot in a route and re-arranges the order of nodes at this depot \n",
    "def mutation(crossedPair, mutationRate):\n",
    "    # get genome routeA\n",
    "    routeA = crossedPair[0]\n",
    "    # get genome routeB\n",
    "    routeB = crossedPair[1]\n",
    "    # get MUTATION_RATE\n",
    "    MUTATION_RATE = mutationRate\n",
    "    # randomly generate a decisive float\n",
    "    decision = random.uniform(0, 1)\n",
    "    \n",
    "    # check if mutation is active\n",
    "    if decision < MUTATION_RATE:\n",
    "        # select random mutation point\n",
    "        mutationPoint = random.choice(depot_locations)\n",
    "        # extract routes of the mutation point (extract nodes from depot)\n",
    "        toMutateRouteA = routeA[mutationPoint]\n",
    "        toMutateRouteB = routeB[mutationPoint]\n",
    "        # mutate routes (re-arrange the node order) \n",
    "        mutateRouteA = random.sample(toMutateRouteA, k=len(toMutateRouteA))\n",
    "        mutateRouteB = random.sample(toMutateRouteB, k=len(toMutateRouteB))\n",
    "        # set the mutated routes as offsprings \n",
    "        routeA[mutationPoint] = mutateRouteA\n",
    "        routeB[mutationPoint] = mutateRouteB\n",
    "        # return mutated routes\n",
    "        return routeA, routeB\n",
    "\n",
    "    # other wise return non-mutated routes\n",
    "    return routeA, routeB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to elect two routes (with poor fitness/largest ovr. distance) to be replaced with the new off spring\n",
    "def replacePopulation(population, popWeight, newPair):\n",
    "\n",
    "    # sort the population index in descending order via weight (index of longest distance first)\n",
    "    sortPopWeight = sorted(popWeight.items(), key=lambda idx: idx[1], reverse=True)\n",
    "\n",
    "    # initialise popIdxToReplace list to store indexes of the less fit genomes to be replaced \n",
    "    popIdxToReplace = []\n",
    "    for sortedWeightIdx in sortPopWeight:\n",
    "        # check for the number of genomes to be replaced \n",
    "        if len(popIdxToReplace) != int(len(newPair)):\n",
    "            popIdxToReplace.append(sortedWeightIdx[0])\n",
    "    \n",
    "    # verify replacement constraints\n",
    "    if len(popIdxToReplace)==len(newPair):\n",
    "        # enumerate popIdxToReplace, so that each population index can be replaced with the corresponding index of newPair\n",
    "        for i, popIdx in enumerate(popIdxToReplace):\n",
    "            # replace population index with corresponding index of the offspring routes\n",
    "            population[popIdx] = newPair[i]\n",
    "    \n",
    "    # return the updated population\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to retain fitter population of routes in the next iterations (preserves 50% from previous iteration)\n",
    "def retainBestRoutes(currentPopulation, popWeight):\n",
    "\n",
    "    # sort the population index in ascending order (shortest ovr. distance to largest over. distance)\n",
    "    sortPopWeight = sorted(popWeight.items(), key=lambda idx: idx[1])\n",
    "    \n",
    "    # initilaise popRetainIdx list to store indexes of population to retain\n",
    "    popIdxToRetain = []\n",
    "    for sortedWeightIdx in sortPopWeight:\n",
    "        # check loop for 50% of the popluation \n",
    "        if len(popIdxToRetain) != int(len(currentPopulation)/2):\n",
    "            popIdxToRetain.append(sortedWeightIdx[0])\n",
    "    \n",
    "    # initialise popRetain list to store list of population\n",
    "    popRetain = []\n",
    "    # match popIdx with currentPopulation to append to popRetain list\n",
    "    for popIdx in popIdxToRetain:\n",
    "        popRetain.append(currentPopulation[popIdx])\n",
    "    \n",
    "    # return list of population to retain for next iteration\n",
    "    return popRetain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to elicit best route per iteration \n",
    "def getBestRoute(currentPopulation, popWeight):\n",
    "    # sort weights in ascending order and extract the index of the shortest overall route\n",
    "    sortPopWeight = sorted(popWeight.items(), key=lambda idx: idx[1])\n",
    "    bestRouteIdx, routeDistance = sortPopWeight[0][0], sortPopWeight[0][1]\n",
    "    bestRoute = currentPopulation[bestRouteIdx]\n",
    "    return bestRoute, routeDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run genetic algorithm to search for the most optimal route; termination criteria = iterations [keep 'size' EVEN int]\n",
    "def runGeneticAlgorithm(cluster, size, iterationLimit, edges):\n",
    "    \n",
    "    # generate initial population \n",
    "    population = population_init(cluster, size)\n",
    "    # initialise list to store upcoming population\n",
    "    nextPopulation = []\n",
    "    # set iteration count to 0\n",
    "    iteration = 0\n",
    "\n",
    "    # while iteration limit not exceeded\n",
    "    while iteration < iterationLimit:\n",
    "        print(f'\\n\\niteration: {iteration}')\n",
    "        # check for retained population \n",
    "        if nextPopulation:\n",
    "            population = nextPopulation\n",
    "            # if population list has enough set of routes \n",
    "            if int(len(population)) != int(len(population)*2):\n",
    "                # generate half the number of initial size to append to the existing list of population NB! key[0] to unpack list\n",
    "                population.append(population_init(cluster, int(size/2))[0])\n",
    "            print(f'population: {population}')\n",
    "        \n",
    "        # get initial fitness of each routes and assign the value as weights per genome \n",
    "        popWeights = fitness(population, edges)[1]\n",
    "        # select two parent genomes (two routes)\n",
    "        selectionPair = selection(population, popWeights)\n",
    "        # perform the crossover operation \n",
    "        crossedPair = crossover(selectionPair)\n",
    "        # mutation stage and not 'mutated' because mutation occurs at random rates\n",
    "        mutationStagePair = mutation(crossedPair, mutationRate=0.4)\n",
    "        # replace the population with new offsprings at the corresponding indexes\n",
    "        population = replacePopulation(population, popWeights, mutationStagePair)\n",
    "        # get the new fitness per route in the population index\n",
    "        popWeights = fitness(population, edges)[1]\n",
    "        # filter populations to preserve '50%' of the fittest routes in the current population for next iteration\n",
    "        nextPopulation = retainBestRoutes(population, popWeights)\n",
    "        print(f'nextPopulation: {nextPopulation}')\n",
    "\n",
    "        # iteration increment\n",
    "        iteration += 1\n",
    "    \n",
    "    # reset popWeights after loop to eval. new pop\n",
    "    popWeights = fitness(population, edges)[1]\n",
    "\n",
    "    # gets the shortest route found and the route distance\n",
    "    bestRoute = getBestRoute(population, popWeights)\n",
    "\n",
    "    # return the bestRoute along with route distance (tuple)\n",
    "    return bestRoute\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the results of runGeneticAlgorithm() in getRoute\n",
    "getRoute = runGeneticAlgorithm(cluster=cluster, size=4, iterationLimit=4, edges=edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best route found by the G.A.\n",
    "bestRoute = getRoute[0]\n",
    "# get the distance of the best route\n",
    "routeDistance = getRoute[1]\n",
    "# display route and distance\n",
    "print(f'{bestRoute}\\n\\n{routeDistance}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initailise routes dict \n",
    "routes = {}\n",
    "\n",
    "# loop through lorry_df index\n",
    "for i in lorry_df.index:\n",
    "    # for each lorry, initialise journey by appending start (depot) and capacity (self)\n",
    "    routes.update({lorry_df['lorry_id'][i]:[[int(lorry_df.depot[i]), lorry_df.capacity[i]]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display routes\n",
    "print(routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise routeTotalCost list to store route costs\n",
    "routeTotalCost = []\n",
    "# initialise totalGasDelivered list to store the amount of gas delivered\n",
    "totalGasSupplied = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tempRoutes = {'124-0': [[124, 8]], '124-1': [[124, 8]], '124-2': [[124, 16]], '124-3': [[124, 25]], '127-0': [[127, 8]], '127-1': [[127, 16]], '127-2': [[127, 25]], '167-0': [[167, 8]], '167-1': [[167, 16]], '167-2': [[167, 16]], '167-3': [[167, 25]], '523-0': [[523, 8]], '523-1': [[523, 16]], '523-2': [[523, 25]]}\n",
    "#tempCluster = {124: [418, 170, 627, 327, 129, 633, 492, 369, 626, 87, 542, 196, 263, 561, 264, 252, 336, 476, 461, 140, 43, 297, 254, 266, 209, 566, 210, 15, 71, 470, 130, 288, 606, 149, 572, 278, 616, 37, 321, 10, 281, 503], 127: [471, 534, 562, 26, 269, 357, 416, 583, 178, 126, 609, 302, 215, 279, 96, 198, 586, 515, 387, 77, 532, 151], 167: [514, 316, 144, 469, 190, 25, 548, 86, 466, 155, 454, 348, 390, 313, 431, 282, 398, 468, 478, 381, 356, 569, 64, 243, 489, 166, 75, 72, 595, 193, 513, 615, 580, 485, 393, 319, 621, 22, 141, 20], 523: [497, 564, 235, 508, 332, 152, 276, 338, 630, 490, 176, 7, 401, 367, 456, 588, 253]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(lorryId, allocatedCustomers):\n",
    "    # get currentId of lorry\n",
    "    currentId = lorryId\n",
    "    # get base depot of lorry\n",
    "    operatingDepot = currentId.split('-')[0]\n",
    "    # get currentCapacity of lorry\n",
    "    currentCapacity = float(lorry_df[lorry_df['lorry_id']==currentId].capacity)\n",
    "    # get currentCpm of lorry\n",
    "    currentCpm = float(lorry_df[lorry_df['lorry_id']==currentId].cpm)\n",
    "    # get currentCptm of lorry\n",
    "    currentCptm = float(lorry_df[lorry_df['lorry_id']==currentId].cptm)\n",
    "    # get currentState of lorry\n",
    "    currentState = int(lorry_df[lorry_df['lorry_id']==currentId].depot)\n",
    "    # get current depot of lorry\n",
    "    currentDepot = int(lorry_df[lorry_df['lorry_id']==currentId].depot)\n",
    "    # set next customer capacity at 0\n",
    "    nextCustomerCapacity = 0\n",
    "\n",
    "    # iterate while the lorry capacity is >= the remaining customer capacity and while their are remaining allocated customers\n",
    "    while (currentCapacity >= nextCustomerCapacity) and (len(allocatedCustomers)>0):\n",
    "        # set next element in allocatedCustomers as the nextCustomer\n",
    "        nextCustomer = next_customer(allocatedCustomers)\n",
    "\n",
    "        # check if next customer tank capacity is more than 80%\n",
    "        if ((location_df[location_df['id']==nextCustomer]['capacity'].iloc[0])-float(location_df[location_df['id']==nextCustomer]['required'].iloc[0])) < ((location_df[location_df['id']==nextCustomer]['capacity'].iloc[0])):\n",
    "        # if float((location_df[location_df['id']==nextCustomer]['capacity'].iloc[0])-(location_df[location_df['id']==nextCustomer]['required'].iloc[0]))<float((location_df[location_df['id']==nextCustomer]['capacity'].iloc[0])*float(0.8)):\n",
    "            # prepare 80% fuel amount to fill up to 80% of relative customer tank capacity\n",
    "            fillAmount = float((location_df[location_df['id']==nextCustomer]['capacity'].iloc[0])*float(0.8))-float(location_df[location_df['id']==nextCustomer]['required'].iloc[0])\n",
    "            # add the amount of gas supplied to totalGasDelivered\n",
    "            totalGasSupplied.append(fillAmount)\n",
    "            routes[currentId].append([int(nextCustomer), -fillAmount])\n",
    "            #tempRoutes[currentId].append([int(nextCustomer), -fillAmount])\n",
    "            # get the cost of traversing between each node links when travelling to nextCustomer node (round to 2 d.p.)\n",
    "            routeCost = round(sum(routing(currentState, nextCustomer, edges)[2])*(currentCpm+(currentCapacity*currentCpm)), 2)\n",
    "            # append routeCost to routeTotalCost list for post-route cost eval.\n",
    "            routeTotalCost.append(routeCost)\n",
    "            # update the current lorry capacity after gas deposit\n",
    "            currentCapacity = currentCapacity-(location_df[location_df['id']==nextCustomer]['required'].iloc[0])\n",
    "            # update the allocatedCustomer's list by removing the served customers\n",
    "            allocatedCustomers.remove(nextCustomer)\n",
    "            # update the lorry's currentState \n",
    "            currentState = nextCustomer\n",
    "\n",
    "        # check if customer tank space is less than 80% of their capacity (then they do not require filling)\n",
    "        elif ((location_df[location_df['id']==nextCustomer]['capacity'].iloc[0])-float(location_df[location_df['id']==nextCustomer]['required'].iloc[0])) > ((location_df[location_df['id']==nextCustomer]['capacity'].iloc[0])):\n",
    "        # elif float((location_df[location_df['id']==nextCustomer]['capacity'].iloc[0])-(location_df[location_df['id']==nextCustomer]['required'].iloc[0]))>float((location_df[location_df['id']==nextCustomer]['capacity'].iloc[0])*float(0.8)):\n",
    "            # -0 deposit since customer doesn't require filling\n",
    "            fillAmount = float(0)\n",
    "            routes[currentId].append([int(nextCustomer), -fillAmount])\n",
    "            #tempRoutes[currentId].append([int(nextCustomer), -fillAmount])\n",
    "            # get the cost of traversing between each node links when travelling to nextCustomer node (round to 2 d.p.)\n",
    "            routeCost = round(sum(routing(currentState, nextCustomer, edges)[2])*(currentCpm+(currentCapacity*currentCpm)), 2)\n",
    "            # append routeCost to routeTotalCost list for post-route cost eval.\n",
    "            routeTotalCost.append(routeCost)\n",
    "            # update the current lorry capacity after gas deposit\n",
    "            currentCapacity = currentCapacity-(location_df[location_df['id']==nextCustomer]['required'].iloc[0])\n",
    "            # if tank capacity is above 80% then remove customer as they do not require filling\n",
    "            allocatedCustomers.remove(nextCustomer)\n",
    "            # update the lorry's currentState \n",
    "            currentState = nextCustomer\n",
    "\n",
    "        # check for remaining allocated customers\n",
    "        if len(allocatedCustomers) != 0:\n",
    "            # set nextCustomerCapacity to the nearest customer's capacity for consecutive iterations\n",
    "            nextCustomerCapacity = location_df[location_df['id']==(next_customer(allocatedCustomers))]['required'].iloc[0]\n",
    "\n",
    "    # if lorry's currentCapacity < nextCustomerCapacity\n",
    "    if currentCapacity < nextCustomerCapacity:\n",
    "        # update the cluster's customer list with the current set of allocatedCustomers\n",
    "        cluster[currentDepot]=allocatedCustomers\n",
    "        # print current lorry's end of route\n",
    "        print(f'{currentId} finished operating at {currentState}')\n",
    "    \n",
    "    # check if any allocated customers remaining\n",
    "    elif len(allocatedCustomers)==0:\n",
    "        # print current lorry's  end of route\n",
    "        print(f'{currentId} finished operating at {currentState}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each depot in depot_locations\n",
    "for i in depot_locations:\n",
    "    # initialise relative dataframe for lorries at each depot\n",
    "    df = lorry_df[lorry_df['depot']==f'{i}']\n",
    "    # set count to 0\n",
    "    count = 0 \n",
    "\n",
    "    # loop through each index per in-loop defined df (of depot-relative lorries)\n",
    "    for j in df.index:\n",
    "        # print start of lorry's route\n",
    "        print(f'{df.loc[j].lorry_id} started operating')\n",
    "        # call route() for each lorry in the relative depot\n",
    "        route(df.loc[j].lorry_id, bestRoute[i])\n",
    "        # count increment\n",
    "        count += 1\n",
    "        \n",
    "        # check if depot's allocated customers remaining\n",
    "        if len(bestRoute[i])!=0 and count==len(df.index): \n",
    "            # while depot has customers remaining\n",
    "            while len(bestRoute[i]!=0):\n",
    "                # set currentId to relative lorry's ID\n",
    "                currentId = lorry_df.loc[j]['lorry_id']\n",
    "                # get the last state of the relative lorry from routes dict\n",
    "                currentState = routes[currentId][-1][0]\n",
    "                # find the nearest depot from the lorry's current state\n",
    "                nearDepot = nearest_depot(currentState)\n",
    "                # print refill statement\n",
    "                print(f'{currentId} is refilling tank at {nearDepot[0]}')\n",
    "                # get the cost of traversing between each node links when travelling to nearDepot node (round to 2 d.p.)\n",
    "                routeCost = round(sum(routing(currentState, nearDepot[0], edges)[2])*((lorry_df.loc[j]['cpm'])+(lorry_df.loc[j]['capacity']*lorry_df.loc[j]['cptm'])), 2)\n",
    "                # append routeCost to routeTotalCost list for post-route cost eval.\n",
    "                routeTotalCost.append(routeCost)\n",
    "                # update routes dict with new state and refill amount\n",
    "                routes[currentId].append([int(nearDepot[0]),int(lorry_df.loc[j]['capacity'])])\n",
    "                #tempRoutes[currentId].append([int(nearDepot[0]),int(lorry_df.loc[j]['capacity'])])\n",
    "                # update currentState to nearDepot\n",
    "                currentState = nearDepot[0]\n",
    "                # call route() for the relative lorry with the relative allocated customers\n",
    "                route(currentId, bestRoute[i])\n",
    "        # check if depot has customers remaining\n",
    "        elif len(bestRoute[i])==0:\n",
    "            # end loop if no customers remaining\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costEfficiency = sum(totalGasSupplied)/sum(routeTotalCost)\n",
    "print(f'TOTAL GAS SUPPLIED: {sum(totalGasSupplied)}\\nPATH COST: {round(sum(routeTotalCost), 2)}\\nCOST EFFICIENCY: {costEfficiency}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise results list\n",
    "results = []\n",
    "# store the lorry_id and relative traversal made in routes to results\n",
    "for i in routes.keys():\n",
    "    results.append({'lorry_id':i, 'traversal':routes[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an encoder class which helps to make the results list json serializable \n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "         if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "         elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "         elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "         else:\n",
    "            return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open new file 'task1_solution.json' as file for outputting results in json format\n",
    "with open('task2_solution.json', 'w') as file:\n",
    "    # use json.dump() to convert type(results) to json and stream to filepath \n",
    "    json.dump(results, file, cls=NpEncoder)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7370fec6be111b608cc34d50d3192bee79c029552a2dcb4c2363d9b827a0176"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
