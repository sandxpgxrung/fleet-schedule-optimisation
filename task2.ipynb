{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location dataframe\n",
    "location_df = pd.read_csv('SaO_Optilandia_resub_locations.csv')\n",
    "\n",
    "# links dataframe\n",
    "links_df = pd.read_csv('SaO_Optilandia_resub_links.csv')\n",
    "\n",
    "# extract lorry data from json\n",
    "lorry_data = json.load(open('SaO_Optilandia_resub_depot_lorries.json', 'r'))\n",
    "\n",
    "# set count to 0\n",
    "k = 0\n",
    "\n",
    "# initialise lorry list\n",
    "lorry = []\n",
    "\n",
    "# loop -> set i to the respective lorry key\n",
    "for i in lorry_data.keys():\n",
    "    # set j to the the number of lorries at key 'i'\n",
    "    for j in range(0, len(lorry_data[i])):\n",
    "        # append each lorry in lorry_data to lorry list\n",
    "        lorry.append(pd.DataFrame(lorry_data[i][j], index=[k]))\n",
    "        # accumulate index\n",
    "        k += 1\n",
    "\n",
    "# lorry dataframe\n",
    "lorry_df = pd.concat(lorry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting required column \n",
    "location_df['required'] = location_df['capacity']-location_df['level']\n",
    "\n",
    "# displaying rows where is_customer true\n",
    "location_df[location_df['is_customer']==True].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 'depot' column to lorry_df and updae with the lorry's relative depot \n",
    "lorry_df['depot'] = lorry_df.lorry_id.apply(lambda x: x.split('-')[0])\n",
    "lorry_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of depot locations (where nodes == depot)\n",
    "depot_locations = np.where(location_df.is_depot)[0]\n",
    "\n",
    "# list of customer locations (where nodes == customers)\n",
    "customer_locations = np.where(location_df.is_customer)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports + visualising the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# parwise distance calculation for each node\n",
    "euclidean = squareform(pdist(location_df[['x', 'y']]))\n",
    "\n",
    "# edges list initialisation\n",
    "edges = []\n",
    "\n",
    "# loop through links_df rows\n",
    "for _, (i, j) in links_df.iterrows():\n",
    "    # append node at i, node at j, and their pairwise distance to edges\n",
    "    edges.append((i, j, euclidean[i, j]))\n",
    "\n",
    "# pos dict intialisation\n",
    "pos = {}\n",
    "\n",
    "# loop through location_df rows\n",
    "for k, v in location_df[['x', 'y']].iterrows():\n",
    "    # update pos dict with array of k, v \n",
    "    pos.update({k:v.values})\n",
    "\n",
    "# initialise depot_labels dict\n",
    "depot_labels = {}\n",
    "\n",
    "# loop throgugh depot_locations\n",
    "for i in depot_locations:\n",
    "    # update depot_labels dict with {i:i}\n",
    "    depot_labels.update({i:i})\n",
    "\n",
    "# initialise customer_labels dict\n",
    "customer_labels = {}\n",
    "\n",
    "# loop through customer_locations\n",
    "for i in customer_locations:\n",
    "    # update customer_labels dict with {i:i}\n",
    "    customer_labels.update({i:i})\n",
    "\n",
    "# initialise nx Graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# feed node list to G\n",
    "G.add_nodes_from(location_df['id'].to_numpy())\n",
    "\n",
    "# feed edges list to G\n",
    "G.add_weighted_edges_from(edges)\n",
    "\n",
    "# resize figure \n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# sketch graph\n",
    "nx.draw(G, pos=pos, node_size=40)\n",
    "\n",
    "# label depot nodes\n",
    "nx.draw_networkx_labels(G, pos, depot_labels)\n",
    "\n",
    "# label customer nodes\n",
    "nx.draw_networkx_labels(G, pos, customer_labels)\n",
    "\n",
    "# mark depot nodes\n",
    "nx.draw_networkx_nodes(G, pos=pos, nodelist=depot_locations, node_color='r', node_size=400, alpha=0.9)\n",
    "\n",
    "# mark customer nodes\n",
    "nx.draw_networkx_nodes(G, pos=pos, nodelist=customer_locations, node_color='g', node_size=200, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clustering nodes ... (nearest-neighbour approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialise cluster dict\n",
    "cluster = {124:[], 127:[], 167:[], 523:[]}\n",
    "\n",
    "# intialise nodes list\n",
    "nodes = [] \n",
    "\n",
    "# loop through each node in customer_locations\n",
    "for node in customer_locations:\n",
    "    # check if node in nodes\n",
    "    if node not in nodes:\n",
    "        # initialise dist list\n",
    "        dist = []\n",
    "        # loop through each depot key\n",
    "        for depot in cluster.keys():\n",
    "            # append euclidean weights to dist \n",
    "            dist.append(euclidean[node, depot])\n",
    "        # get shortest distance\n",
    "        shortestDist = min(dist)\n",
    "        # match shortest distance to equivalent node index\n",
    "        nearestDepotIndex = np.where(euclidean[node]==shortestDist)\n",
    "        # add node to relative nearest depot location\n",
    "        cluster[int(nearestDepotIndex[0])].append(node)\n",
    "        # track applied nodes\n",
    "        nodes.append(node)\n",
    "        # clear dist\n",
    "        dist.clear()\n",
    "\n",
    "# print allocated nodes to relative cluster points (depot locations)\n",
    "print(cluster)\n",
    "\n",
    "# clear nodes list\n",
    "nodes.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "discrete genetic algorithm (breadth-first-search used for pathfinding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initailise routes dict \n",
    "routes = {}\n",
    "\n",
    "# loop through lorry_df index\n",
    "for i in lorry_df.index:\n",
    "    # for each lorry, initialise journey by appending start (depot) and capacity (self)\n",
    "    routes.update({lorry_df['lorry_id'][i]:[(lorry_df.depot[i]), lorry_df.capacity[i]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display routes so far\n",
    "routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import random\n",
    "\n",
    "# function to generate a random path order for each depot # returns a dict \n",
    "def randomPathArrangement(cluster):\n",
    "    randomPathArr = {}\n",
    "    customerAllocation = cluster\n",
    "    for depot in depot_locations:\n",
    "        randomPathArr.update({depot:random.sample(customerAllocation[depot], len(customerAllocation[depot]))})\n",
    "    return randomPathArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(randomPathArrangement(cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate multiple initial solutions (population) # returns genomes (individual solution) as a list\n",
    "def population_init(cluster, size):\n",
    "    population = []\n",
    "    for i in range(0, size):\n",
    "        population.append(randomPathArrangement(cluster))\n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(population_init(cluster, 2))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7370fec6be111b608cc34d50d3192bee79c029552a2dcb4c2363d9b827a0176"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
