{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- problem definition: \n",
    "Task 1: Minimise the overall delivery time and cost of delivery.\n",
    "Task 2: Maximise cost-efficiency (total gas delivered/overall cost of delivery)\n",
    "# In both cases: \n",
    "The task is to efficiently distribute fuel across a number of customer nodes. It is in mind to use each depot to their fullest potential through means such as clustering of nodes. The problem is at first glance, a combinatorial problem as it introduces the need for optimising many parameters to find the most optimal task route. \n",
    "\n",
    "- Constraints:\n",
    "Task 1: Deliver to customers with less gas than 50% of their tank's capacity.\n",
    "Task 2: Deliver to customers with less gas than 80% of their tank's capacity and fill up to 80% of their tank's capacity.\n",
    "\n",
    "- optimization algorithm (+ others): \n",
    "Task 1: Greedy search algorithm, Breadth-First-Search algorithm\n",
    "Task 2: Continuous Genetic Algorithm, Breadth-First-Search algorithm\n",
    "\n",
    "- results:\n",
    "outputted to task1_solution.json file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- methodology:\n",
    "\n",
    "1. Converting the .csv files into pandas dataframe (using pandas library)\n",
    "\n",
    "Firstly I converted the data stored in .csv files into a pandas dataframe. There are many advantages to this (1), as well as some disadvantages (2): \n",
    "+ Python supported operations \n",
    "+ NumPy supported operations \n",
    "+ Extensive set of feature techniques \n",
    "+ Readable syntax \n",
    "+ Cleaner representation of data structures \n",
    "+ Conversion of .csv to a tabular format\n",
    "- Documenation (less coverage on the harder functions of pandas library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE FOR .CSV FILE CONVERSION INTO PANDAS \n",
    "\n",
    "# relevant imports \n",
    "import pandas as pd \n",
    "\n",
    "# location dataframe\n",
    "location_df = pd.read_csv('SaO_Optilandia_resub_locations.csv')\n",
    "\n",
    "# visual representation of location_df in tabular format\n",
    "location_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implementing the use of numPy library to process data series from a pandas dataframe\n",
    "\n",
    "NumPy library deemed important for processing and operating on large data structures stored in the relative dataframes. The advantages and disadvantages of using NumPy library include (3): \n",
    "\n",
    "+ As opposed to the tabular data representation in Pandas used mainly for analysing data, NumPy offers multi-dimensional arrays and matrix datastructures for performing mathematical operations.\n",
    "- Some numpy values can cause ambiguity issues in pythons interprerator and additional processing steps may be required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE EXAMPLE FOR USING NUMPY FOR EXTRACTING PANDAS ROWS WHERE CONDITION IS MET\n",
    "\n",
    "# relevant imports \n",
    "import numpy as np\n",
    "\n",
    "# list of depot locations (where nodes == depot)\n",
    "depot_locations = np.where(location_df.is_depot)[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Graph visualisation and euclidean distance\n",
    "\n",
    "The networkx library was implemented to visualise the network of customer and depot nodes stored in the pandas dataframe.\n",
    "Why networkx? \n",
    "+ supports mapping of nodes, edges with arbritrary data, and analysis of network structure (6).\n",
    "\n",
    "The scipy library was used to support the calculation of euclidean distance betwene two nodes. This library supports matrix computation of vector observations that are stored in an array (7). This made the the extraction of spatial distance between any two given nodes a consistent process throughout both tasks 1 and 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE FOR MATRIX CALCULATION OF SPATIAL DISTANCE BETWEEN ALL NODES STORED IN THE ARRAY\n",
    "\n",
    "# relevant imports \n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "# parwise distance calculation for each node\n",
    "euclidean = squareform(pdist(location_df[['x', 'y']]))\n",
    "\n",
    "# edges list initialisation\n",
    "edges = []\n",
    "\n",
    "# links dataframe\n",
    "links_df = pd.read_csv('SaO_Optilandia_resub_links.csv')\n",
    "\n",
    "# loop through links_df rows\n",
    "for _, (i, j) in links_df.iterrows():\n",
    "    # append node at i, node at j, and their pairwise distance to edges\n",
    "    edges.append((i, j, euclidean[i, j]))\n",
    "\n",
    "# displaying first 5 edges in the edges list\n",
    "print(f'#EDGES# (nodeA, nodeB, distance): {edges[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE FOR VISUALISATION OF THE NETWORK\n",
    "\n",
    "# relevant imports \n",
    "import networkx as nx \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pos dict intialisation\n",
    "pos = {}\n",
    "\n",
    "# loop through location_df rows\n",
    "for k, v in location_df[['x', 'y']].iterrows():\n",
    "    # update pos dict with array of k, v \n",
    "    pos.update({k:v.values})\n",
    "\n",
    "# initialise depot_labels dict\n",
    "depot_labels = {}\n",
    "\n",
    "# loop throgugh depot_locations\n",
    "for i in depot_locations:\n",
    "    # update depot_labels dict with {i:i}\n",
    "    depot_labels.update({i:i})\n",
    "\n",
    "# initialise customer_labels dict\n",
    "customer_labels = {}\n",
    "\n",
    "# list of customer locations (where nodes == customers)\n",
    "customer_locations = np.where(location_df.is_customer)[0]\n",
    "\n",
    "# loop through customer_locations\n",
    "for i in customer_locations:\n",
    "    # update customer_labels dict with {i:i}\n",
    "    customer_labels.update({i:i})\n",
    "\n",
    "# initialise nx Graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# feed node list to G\n",
    "G.add_nodes_from(location_df['id'].to_numpy())\n",
    "\n",
    "# feed edges list to G\n",
    "G.add_weighted_edges_from(edges)\n",
    "\n",
    "# resize figure \n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# sketch graph\n",
    "nx.draw(G, pos=pos, node_size=40)\n",
    "\n",
    "# label depot nodes\n",
    "nx.draw_networkx_labels(G, pos, depot_labels)\n",
    "\n",
    "# label customer nodes\n",
    "nx.draw_networkx_labels(G, pos, customer_labels)\n",
    "\n",
    "# mark depot nodes\n",
    "nx.draw_networkx_nodes(G, pos=pos, nodelist=depot_locations, node_color='r', node_size=400, alpha=0.9)\n",
    "\n",
    "# mark customer nodes\n",
    "nx.draw_networkx_nodes(G, pos=pos, nodelist=customer_locations, node_color='g', node_size=200, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Clustering (based on the notion of nearest-neighbours)\n",
    "\n",
    "Objective: finding the partition of data set, assigning each data (customer nodes) in the sample to four distinct points (depot nodes). \n",
    "\n",
    "A self-implemented clustering program was used for allocating customers to relative depots. This program takes into account the spatial distance between each customer node to all depot nodes, assigning them to the depot they are nearest to. In essence, the algorithm is 'based' on the notion of 'nearest-neighbour' because it is likely that closer nodes are likely to have less overall traversal time. However, this notion can be countered when taking road links into account, therefore, an algorithm that examines the complete breadth of a path (hence, why we have used breadth-first-search as discussed later on). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE FOR CLUSTERING OF NODES\n",
    "\n",
    "# intialise cluster dict\n",
    "cluster = {124:[], 127:[], 167:[], 523:[]}\n",
    "\n",
    "# intialise nodes list\n",
    "nodes = [] \n",
    "\n",
    "# loop through each node in customer_locations\n",
    "for node in customer_locations:\n",
    "    # check if node in nodes\n",
    "    if node not in nodes:\n",
    "        # initialise dist list\n",
    "        dist = []\n",
    "        # loop through each depot key\n",
    "        for depot in cluster.keys():\n",
    "            # append euclidean weights to dist \n",
    "            dist.append(euclidean[node, depot])\n",
    "        # get shortest distance\n",
    "        shortestDist = min(dist)\n",
    "        # match shortest distance to equivalent node index\n",
    "        nearestDepotIndex = np.where(euclidean[node]==shortestDist)\n",
    "        # add node to relative nearest depot location\n",
    "        cluster[int(nearestDepotIndex[0])].append(node)\n",
    "        # track applied nodes\n",
    "        nodes.append(node)\n",
    "        # clear dist\n",
    "        dist.clear()\n",
    "\n",
    "# print allocated nodes to relative cluster points (depot locations)\n",
    "print(cluster)\n",
    "\n",
    "# clear nodes list\n",
    "nodes.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Breadth-First-Search (BFS) Algorithm ### PATH FINDING ###\n",
    "\n",
    "A self-implemented pathfinding program based on the notion of breadth-first-search was used for retrieiving the shortest order of traversals between two nodes. The main idea is the use queue and visit every adjacent node to the most recent node visited. When the destination node has been reached, we can backtrace through all the relative traversals made between the starting node and the final node to get the shortest route between the nodes in the graph. In this context, since route id's are independent of node id's; 'edge memory' list was additionaly introduced to store the set of explored edges (used in backtracing as shown in the example code below).\n",
    "\n",
    "+ nb: the distance between two nodes were featured as the edge weights.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE FOR BREADTH-FIRST-SEARCH ALGORITHM FOR PATHFINDING SHORTEST ROUTE BETWEEN TWO NODES\n",
    "\n",
    "# Routing from A to B using recursive Breadth-First-Search based algorithm to find shortest route, with back tracing\n",
    "def routing(currState, toState, edges):\n",
    "    # intialise visitedState list for tracking node traversal\n",
    "    visitedState = [currState]\n",
    "    # initialise visitedEdge list for tracking edge traversal\n",
    "    visitedEdge = []\n",
    "    # intialise edgeMemory list for storing the explored edges\n",
    "    edgeMemory = []\n",
    "    # intialise queue list for choosing the central node for next traversal\n",
    "    queue = [currState]\n",
    "\n",
    "    # loop while toState is not found\n",
    "    while currState != toState:\n",
    "        # remove and store the last element of the queue list as q\n",
    "        q = queue.pop(0)\n",
    "        \n",
    "        # intialise currEdges dict which holds the next set of edges for traversals\n",
    "        currEdges = {}\n",
    "        # get the nodes at each edge, where either nodes are equivalent to q\n",
    "        for edge in list(np.where(links_df[['id1', 'id2']]==q)[0]):\n",
    "            # update the dict with the relative edge key and the node pairs\n",
    "            currEdges.update({edge:[edges[edge][0], edges[edge][1]]})\n",
    "        \n",
    "        # store the explored edges in edgeMemory list\n",
    "        edgeMemory.append(currEdges)\n",
    "\n",
    "        # loop through each edge in currEdges\n",
    "        for edge in currEdges:\n",
    "            # check if the edge has been visited \n",
    "            if edge not in visitedEdge:\n",
    "                # if not visited then add the edge to visitedEdge\n",
    "                visitedEdge.append(edge)\n",
    "                # check the node index in the edge that has not been visited \n",
    "                if currEdges[edge][0] not in visitedState and currEdges[edge][1] in visitedState:\n",
    "                    # set currState to the unvisited node \n",
    "                    currState = currEdges[edge][0]\n",
    "                    # mark the node in currState as visited \n",
    "                    visitedState.append(currState)\n",
    "                    # add new currState to queue \n",
    "                    queue.append(currState)\n",
    "                    # check if toState reached\n",
    "                    if currState == toState:\n",
    "                        # set currState to toState\n",
    "                        currState = toState\n",
    "                        # end loop\n",
    "                        break \n",
    "                # similar to above but in the context of different index position of the node that has not been visited\n",
    "                if currEdges[edge][1] not in visitedState and edges[edge][0] in visitedState:\n",
    "                    currState = currEdges[edge][1]\n",
    "                    visitedState.append(currState)\n",
    "                    queue.append(currState)\n",
    "                    if currState == toState:\n",
    "                        currState = toState\n",
    "                        break\n",
    "    \n",
    "    # set startState as the first node in visitedState list\n",
    "    startState = visitedState[0]\n",
    "    # set lastQ as the toState for tracking q node from end of order\n",
    "    lastQ = [toState]\n",
    "    # intialise backtrace list for backtracing the edges from edgeMemory\n",
    "    backtrace = []\n",
    "    # initialise nodetrace list for backtracing the nodes from edgeMemory\n",
    "    nodetrace = []\n",
    "\n",
    "    # intialise edgeMemoryReversed for reordering edgeMemory \n",
    "    edgeMemoryReversed = []\n",
    "    # loop through each index between range 0 and length of edgeMemory\n",
    "    for i in range (0, len(edgeMemory)):\n",
    "        # set endElement to the last element in edgeMemory\n",
    "        endElement = edgeMemory.pop(-1)\n",
    "        # add the endElement to edgeMemoryReversed\n",
    "        edgeMemoryReversed.append(endElement)\n",
    "    \n",
    "    # while last element in lastQ is not equivalent to the startState\n",
    "    while lastQ[-1] != startState:\n",
    "        # loop through each edge options in edgeMemoryReversed\n",
    "        for edgeOpt in edgeMemoryReversed:\n",
    "            # loop through each edge from as keys of the edge options\n",
    "            for edge in edgeOpt.keys():\n",
    "\n",
    "                # check if last element of lastQ is in the set of edge options given the edge\n",
    "                if lastQ[-1] in edgeOpt[edge]:\n",
    "                    # add the edge to backtrace \n",
    "                    backtrace.append(edge)\n",
    "                    # check index of node which matches the lastQ element \n",
    "                    if lastQ[-1] == edgeOpt[edge][0] and lastQ[-1] != edgeOpt[edge][1]:\n",
    "                        # update lastQ as the the node which does not match the lastQ element\n",
    "                        lastQ.append(edgeOpt[edge][1])\n",
    "                        # add the node to nodetrace\n",
    "                        nodetrace.append(edgeOpt[edge][1])\n",
    "                        # return to while iterate\n",
    "                        break\n",
    "                        # similar to above but in the context of different index postion of the matching node with lastQ element\n",
    "                    if lastQ[-1] != edgeOpt[edge][0] and lastQ[-1] == edgeOpt[edge][1]:\n",
    "                        lastQ.append(edgeOpt[edge][0])\n",
    "                        nodetrace.append(edgeOpt[edge][0])\n",
    "                        break\n",
    "    \n",
    "    # re-ordering edges from start to end\n",
    "    edgeTraversed = []\n",
    "    for i in range(0, len(backtrace)):\n",
    "        endElement = backtrace.pop(-1)\n",
    "        edgeTraversed.append(endElement)\n",
    "\n",
    "    # re-ordering nodes from start to end \n",
    "    nodeOrder = []\n",
    "    for i in range(0, len(nodetrace)):\n",
    "        endElement = nodetrace.pop(-1)\n",
    "        nodeOrder.append(endElement)\n",
    "    \n",
    "    # adding route weight (distance between nodes) to each traversal made\n",
    "    routeWeight = []\n",
    "    for edge in edgeTraversed:\n",
    "        routeWeight.append(edges[edge][2])\n",
    "\n",
    "    # return the the order in which nodes were visited and the order in which edges were traversed\n",
    "    return nodeOrder, edgeTraversed, routeWeight\n",
    "\n",
    "# dummy print: for example purpose\n",
    "print(f'nodes order: {routing(124, 10, edges)[0]}')\n",
    "print(f'edges traversed: {routing(124, 10, edges)[1]}')\n",
    "print(f'route weight: {routing(124, 10, edges)[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. task 1\n",
    "# greedy search\n",
    "\n",
    "The greedy algorithm is a search strategy which makes the most optimal decision at each stage [10]. Problems related with small fraction of states, in which sparse-space need to be covered can be addressed by the greedy search strategy [11]. In this context, given a starting node, the next node is chosen via the relative spatial distance between each node. Greedy search strategy has been used as a simple means for minimising the distance travelled or dispatch time, especially since the problem dimension is published on a 2-dimensional (2D) plane.\n",
    "# This concept has been applied in selecting the order in which each allocated customers per depot (nodes per cluster point) are visited.\n",
    "For instance, the most susceptible next node being the closest node to the current node of consideration. This helps minimise distance. However, again since the overall path distance including traversals made from one point to next is not considered, it has blindspots for the distances between those paths, although it is included in the final result. \n",
    "\n",
    "# pseudo-code-architecture for the greedy search function: \n",
    "\n",
    "- parameters: current node, allocated nodes, spatial distance, destination node\n",
    "\n",
    "- function structure: nearest_node(start node, goal node, edge weights) # outputs a destination node based on spatial distance\n",
    "\n",
    "- formulation: destination node = nearest_node(current node, allocated nodes, relative spatial distances)\n",
    "                                = 'relative spatial distance' between 'current node' and 'each node in the allocated nodes'\n",
    "                                = 'the node pair with the shortest spatial distance' (where one of the node is the current node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE CODE FOR GREEDY SEARCH FUNCTIONS\n",
    "\n",
    "# function: finding next nearest customer node\n",
    "def nearest_customer(currentState, customerList):\n",
    "    #initialise dist dict\n",
    "    dist = {}\n",
    "    \n",
    "    # loop through customerList\n",
    "    for i in customerList:\n",
    "        # check for all where customer != currentState\n",
    "        if i != currentState:\n",
    "            # update dist with available customer index and their relative weights\n",
    "            dist.update({i:euclidean[i,currentState]})\n",
    "\n",
    "    # initialise temp list\n",
    "    temp = []\n",
    "\n",
    "    # loop through keys of dist \n",
    "    for i in dist.keys():\n",
    "        # add weights to temp\n",
    "        temp.append(dist[i])\n",
    "    \n",
    "    # get lowest weight\n",
    "    _shortestDist = min(temp)\n",
    "    \n",
    "    # find relative index of lowest weight\n",
    "    nearestCustomerIndex = np.where(euclidean[currentState]==_shortestDist)\n",
    "    \n",
    "    # return next index with relative weight\n",
    "    return int(nearestCustomerIndex[0]), _shortestDist\n",
    "\n",
    "# dummy prints: for example purposes\n",
    "print(f'nearest customer to node 124: {nearest_customer(124, cluster[124])[0]}')\n",
    "print(f'distance: {nearest_customer(124, cluster[124])[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. task 2\n",
    "# genetic algorithm\n",
    "\n",
    "Genetic algorithm searches for the fittest population in a given set of populations and introduces the notion of reproduction in aims of improving the solution. In doing so, the algroithm utilises the notion of natural evolution, which is why they are considered as a branch of evoltuionary algorithms (set of nature based algorithms for problem solving) [12]. Due to the context of the problem, genetic algorithm is an ideal approach for solving np-complete (combinatorial) problems in order to either maximise gain or minimise loss. \n",
    "\n",
    "- Complexity induces time consumption. In this context, using BFS algorithm for evaluating fitness in conjunction with the genetic algorithms fitness function increased the time taken to evaluate the fitness per genome (this will be further discussed in the results).\n",
    "\n",
    "# pseudo-code-architecture for genetic algorithm functions: (defines problem formulation using genetic algorithm structure)\n",
    "\n",
    "Although the code has been documented with inline comments, some general objectives of each function of the algorithm include:\n",
    "- functions: generateGenome(), generatePopulation(), calculateFitness(), selectParents(), crossover(), mutation(), main()\n",
    "NB: the functions in the actual code and this pseudo-code do not share the exact same names. \n",
    "\n",
    "- objectives: \n",
    "\n",
    "+ generateGenome() : The genome in this case is a solution. A solution in this context is the order of customer nodes per depot. The order is significant because it defines the order in which the lorry visits each location (similar to the problem of travelling salesman person). Therefore, it is possible to think of a solution as the order of route assigned per depot. The depots and node allocation in this instance be thought of as genes and chromosomes in the genome respectively. \n",
    "\n",
    "+ generatePopulation() : The population is represented by many number of genomes per set. This is equivalent to having many different number of solutions stored within a list. Some genomes in the populations are retained in future iterations, whereas some are replaced by newer genomes; allowing for the breadth of all possible routes to be explored. \n",
    "\n",
    "+ calculateFitness() : The fitness of a genome is the total weight of chromosomes per segment. In problem context, the fitness of the solution is the total distance of each route per depot, summed up to produce an overall distance for the solution. Any two solutions where routes are ordered differently may or may not produce the same fitness score. \n",
    "\n",
    "+ selectParents() : the selection function chooses two genomes (two solutions) as parents for the mating operation. The selection process in this case is based on the notion of roulette-wheel selection technique. This approach is constructed from the relative fitness of each individual genomes [13]. For instance, each genome is given a selection probability based on their fitness. By avoiding elitism (selecting only the best methods), I have attempted to split this algorithm from the greedy search which only picks the optimal solution at each stage. This is to avoids the risk of local minima but not entirely [14].\n",
    "\n",
    "+ crossover() : the crossover function partitions the genomes are the same segment point. The opposite segments from each genomes are combined to create a new complete solution. In this case the algorithm implements an 'n point' crossover technique where a segment (depot) in the solution is randomly chosen as the cutting point. The solution is sliced and each partition of the solution is combined to the opposite part from the other solution. This is also known as the mating process.\n",
    "\n",
    "+ mutation() : the mutaton function aims to alter the outcome of each solution by altering the solution itself. The mutation is only applied to the offsprings. It consists of a mutation rate which randomly decides whether the mutation should occur or not. In this context, 'n point' mutation technique has been implemented to randomly choose a depot in a solution. The order of route for that depot is rearranged in a random order in aims of producing a new solution. Since, crossovers would likely reproduce solutions that are similar, it is a risk for pre-mature convergence. Whereas, introducing this mutation function gives an opportunity for diversity in the offsprings, countering the risk of converging on a local minima. \n",
    "\n",
    "+ main() : this is a helper function used to run compute the functions in an asynchronous order per iteration. The code has been created with reusability in mind, and such the function can take in a number of variables such as size, iteration, and genome structure. The iteration refers to the termination criteria as well, in which the function loops until the maximum iteration has been met but not exceeded. \n",
    "\n",
    "+ other()'(s) : there are some additional functions that were made to support additional steps for this problem context; such as picking the best solutions per iteration, retaining the best solutions for the next generation, and replacing poorer solutions as well. These are documented inline with the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummyCluster is only generated here for example purpose\n",
    "dummyCluster = {124: [10, 15, 37, 43, 71, 87, 129, 130, 140, 149, 170, 196, 209, 210, 252, 254, 263, 264, 266, 278, 281, 288, 297, 321, 327, 336, 369, 418, 461, 470, 476, 492, 503, 542, 561, 566, 572, 606, 616, 626, 627, 633], 127: [26, 77, 96, 126, 151, 178, 198, 215, 269, 279, 302, 357, 387, 416, 471, 515, 532, 534, 562, 583, 586, 609], 167: [20, 22, 25, 64, 72, 75, 86, 141, 144, 155, 166, 190, 193, 243, 282, 313, 316, 319, 348, 356, 381, 390, 393, 398, 431, 454, 466, 468, 469, 478, 485, 489, 513, 514, 548, 569, 580, 595, 615, 621], 523: [7, 152, 176, 235, 253, 276, 332, 338, 367, 401, 456, 490, 497, 508, 564, 588, 630]}\n",
    "\n",
    "# imports \n",
    "import random\n",
    "\n",
    "# function to generate a random path order (consider as genome) for each depot # returns a dict \n",
    "def randomPathArrangement(cluster):\n",
    "    randomPathArr = {}\n",
    "    customerAllocation = cluster\n",
    "    for depot in depot_locations:\n",
    "        # append depot as key and list of randomly arranged customer nodes to randomPathArr\n",
    "        randomPathArr.update({depot:random.sample(customerAllocation[depot], len(customerAllocation[depot]))})\n",
    "    return randomPathArr\n",
    "\n",
    "# function to generate multiple initial solutions (population) # returns genomes (individual solution) in a list\n",
    "def population_init(cluster, size):\n",
    "    population = []\n",
    "    for i in range(0, size):\n",
    "        population.append(randomPathArrangement(cluster))\n",
    "    return population\n",
    "\n",
    "# return populationFitness at each index...\n",
    "def fitness(population, edges):\n",
    "\n",
    "    # to store each weight per traversal made between two nodes (when calculating traversal distance per depot)\n",
    "    genomeWeight = []\n",
    "\n",
    "    # for a possible solution in the set of solutions (genome in population)\n",
    "    for genome in population:\n",
    "        # initialise genomeFitness dict to store distances at each depot per genome \n",
    "        genomeFitness = {}\n",
    "        for depot in genome.keys():\n",
    "        #for depot in depot_locations:\n",
    "            genomeFitness.update({depot:[]})\n",
    "            nodes = genome[depot]\n",
    "            # loop for length of nodes\n",
    "            for idx in range(len(nodes)-1):\n",
    "                # set nodeA to current loop index\n",
    "                nodeA = nodes[idx]\n",
    "                # set nodeB to next loop index\n",
    "                nodeB = nodes[idx+1]\n",
    "                # get sum of each traversal distance occurence between two nodes | routing() enables this \n",
    "                distance = sum(routing(nodeA, nodeB, edges)[2])\n",
    "                genomeFitness[depot].append(distance)\n",
    "        # update popFitness list with each genome and relative fitness values\n",
    "        genomeWeight.append(genomeFitness)\n",
    "\n",
    "    genomeWeights = []\n",
    "    for genome in genomeWeight:\n",
    "        # initialise popWeight list to store total weight at each depot for genome\n",
    "        depotWeight = []\n",
    "        # loop through each depot (chromosome per genome)\n",
    "        for depot in genome:\n",
    "            depotWeight.append({depot:sum(genome[depot])})\n",
    "        genomeWeights.append(depotWeight)\n",
    "    \n",
    "    # to store the weight per index (weight per genome) [each solution indicated by index i.e., 0, 1, 2 etc.]\n",
    "    weightIndex = {}\n",
    "    for idx, genome in enumerate(genomeWeights):\n",
    "        tempIndexStore = []\n",
    "        for depot in genome:\n",
    "            for i in depot.values():\n",
    "                tempIndexStore.append(i)\n",
    "        weightIndex.update({idx:sum(tempIndexStore)})\n",
    "    \n",
    "    return population, weightIndex\n",
    "\n",
    "# selection() uses weighted selection probability for returning 2 cluster arrangement (2 genomes)\n",
    "def selection(population, popWeights):\n",
    "    # selectionPair defines a list containing # of genomes selected through concept of roulette-wheel (in this case k=2). \n",
    "    selectionPair = random.choices(population=population, weights=popWeights, k=2)\n",
    "    # return the selectionPair (in form list)\n",
    "    return selectionPair \n",
    "\n",
    "# crossover() takes two routes (genomes) and performs crossover operation to produce new routes (offspring)\n",
    "def crossover(selectionPair):\n",
    "    # initialise routeA (i.e., genome 1)\n",
    "    routeA = selectionPair[0]\n",
    "    # initialise routeB (i.e., genome 2)\n",
    "    routeB = selectionPair[1]\n",
    "    \n",
    "    # check if both routes (both genomes) have same number of keys (depots)\n",
    "    if len(routeA.keys()) != len(routeB.keys()):\n",
    "        # give error warning\n",
    "        print(f'#---crossover error---# route depots are not of same length')\n",
    "    # if route keys are of same length then proceed with crossover\n",
    "    else:\n",
    "        # set random crossover point nPoint\n",
    "        nPoint = random.randint(1, len(routeA.keys())-1)\n",
    "        # get routeA.values() up to nPoint \n",
    "        extractRouteA1 = list(routeA.values())[nPoint:]\n",
    "        # get routeB.values() up to nPoint\n",
    "        extractRouteB1 = list(routeB.values())[nPoint:]\n",
    "        # get routeA.values() beyond nPoint\n",
    "        extractRouteA2 = list(routeA.values())[:nPoint]\n",
    "        # get routeB.values() beyond nPoint\n",
    "        extractRouteB2 = list(routeB.values())[:nPoint]\n",
    "\n",
    "        # set offsprings as corresponding concantenation of each route extracts\n",
    "        offspringA = extractRouteB2+extractRouteA1\n",
    "        offspringB = extractRouteA2+extractRouteB1\n",
    "\n",
    "        # intialise offspring dicts\n",
    "        newRouteA = {}\n",
    "        newRouteB = {}\n",
    "\n",
    "        # loop through each depot nodes\n",
    "        for i, depot in enumerate(depot_locations):\n",
    "            # allocate new routes to relative depots\n",
    "            newRouteA.update({depot:offspringA[i]})\n",
    "            newRouteB.update({depot:offspringB[i]})\n",
    "\n",
    "    # return the new offsprings\n",
    "    return newRouteA, newRouteB \n",
    "\n",
    "# mutation() selects a random depot in a route and re-arranges the order of nodes at this depot \n",
    "def mutation(crossedPair, mutationRate):\n",
    "    # get genome routeA\n",
    "    routeA = crossedPair[0]\n",
    "    # get genome routeB\n",
    "    routeB = crossedPair[1]\n",
    "    # get MUTATION_RATE\n",
    "    MUTATION_RATE = mutationRate\n",
    "    # randomly generate a decisive float\n",
    "    decision = random.uniform(0, 1)\n",
    "    \n",
    "    # check if mutation is active\n",
    "    if decision < MUTATION_RATE:\n",
    "        # select random mutation point\n",
    "        mutationPoint = random.choice(depot_locations)\n",
    "        # extract routes of the mutation point (extract nodes from depot)\n",
    "        toMutateRouteA = routeA[mutationPoint]\n",
    "        toMutateRouteB = routeB[mutationPoint]\n",
    "        # mutate routes (re-arrange the node order) \n",
    "        mutateRouteA = random.sample(toMutateRouteA, k=len(toMutateRouteA))\n",
    "        mutateRouteB = random.sample(toMutateRouteB, k=len(toMutateRouteB))\n",
    "        # set the mutated routes as offsprings \n",
    "        routeA[mutationPoint] = mutateRouteA\n",
    "        routeB[mutationPoint] = mutateRouteB\n",
    "        # return mutated routes\n",
    "        return routeA, routeB\n",
    "\n",
    "    # other wise return non-mutated routes\n",
    "    return routeA, routeB\n",
    "\n",
    "# helper function to elect two routes (with poor fitness/largest ovr. distance) to be replaced with the new off spring\n",
    "def replacePopulation(population, popWeight, newPair):\n",
    "\n",
    "    # sort the population index in descending order via weight (index of longest distance first)\n",
    "    sortPopWeight = sorted(popWeight.items(), key=lambda idx: idx[1], reverse=True)\n",
    "\n",
    "    # initialise popIdxToReplace list to store indexes of the less fit genomes to be replaced \n",
    "    popIdxToReplace = []\n",
    "    for sortedWeightIdx in sortPopWeight:\n",
    "        # check for the number of genomes to be replaced \n",
    "        if len(popIdxToReplace) != int(len(newPair)):\n",
    "            popIdxToReplace.append(sortedWeightIdx[0])\n",
    "    \n",
    "    # verify replacement constraints\n",
    "    if len(popIdxToReplace)==len(newPair):\n",
    "        # enumerate popIdxToReplace, so that each population index can be replaced with the corresponding index of newPair\n",
    "        for i, popIdx in enumerate(popIdxToReplace):\n",
    "            # replace population index with corresponding index of the offspring routes\n",
    "            population[popIdx] = newPair[i]\n",
    "    \n",
    "    # return the updated population\n",
    "    return population\n",
    "\n",
    "# helper function to retain fitter population of routes in the next iterations (preserves 50% from previous iteration)\n",
    "def retainBestRoutes(currentPopulation, popWeight):\n",
    "\n",
    "    # sort the population index in ascending order (shortest ovr. distance to largest over. distance)\n",
    "    sortPopWeight = sorted(popWeight.items(), key=lambda idx: idx[1])\n",
    "    \n",
    "    # initilaise popRetainIdx list to store indexes of population to retain\n",
    "    popIdxToRetain = []\n",
    "    for sortedWeightIdx in sortPopWeight:\n",
    "        # check loop for 50% of the popluation \n",
    "        if len(popIdxToRetain) != int(len(currentPopulation)/2):\n",
    "            popIdxToRetain.append(sortedWeightIdx[0])\n",
    "    \n",
    "    # initialise popRetain list to store list of population\n",
    "    popRetain = []\n",
    "    # match popIdx with currentPopulation to append to popRetain list\n",
    "    for popIdx in popIdxToRetain:\n",
    "        popRetain.append(currentPopulation[popIdx])\n",
    "    \n",
    "    # return list of population to retain for next iteration\n",
    "    return popRetain \n",
    "\n",
    "# helper function to elicit best route per iteration \n",
    "def getBestRoute(currentPopulation, popWeight):\n",
    "    # sort weights in ascending order and extract the index of the shortest overall route\n",
    "    sortPopWeight = sorted(popWeight.items(), key=lambda idx: idx[1])\n",
    "    bestRouteIdx, routeDistance = sortPopWeight[0][0], sortPopWeight[0][1]\n",
    "    bestRoute = currentPopulation[bestRouteIdx]\n",
    "    return bestRoute, routeDistance\n",
    "\n",
    "# run genetic algorithm to search for the most optimal route; termination criteria = iterations [keep 'size' EVEN int]\n",
    "def runGeneticAlgorithm(cluster, size, iterationLimit, edges):\n",
    "    \n",
    "    # generate initial population \n",
    "    population = population_init(cluster, size)\n",
    "    # initialise list to store upcoming population\n",
    "    nextPopulation = []\n",
    "    # set iteration count to 0\n",
    "    iteration = 0\n",
    "\n",
    "    # while iteration limit not exceeded\n",
    "    while iteration < iterationLimit:\n",
    "        # print(f'\\n\\niteration: {iteration}')\n",
    "        # check for retained population \n",
    "        if nextPopulation:\n",
    "            population = nextPopulation\n",
    "            # if population list has enough set of routes \n",
    "            if int(len(population)) != int(len(population)*2):\n",
    "                # generate half the number of initial size to append to the existing list of population NB! key[0] to unpack list\n",
    "                population.append(population_init(cluster, int(size/2))[0])\n",
    "            # print(f'population: {population}')\n",
    "        \n",
    "        # get initial fitness of each routes and assign the value as weights per genome \n",
    "        popWeights = fitness(population, edges)[1]\n",
    "        # select two parent genomes (two routes)\n",
    "        selectionPair = selection(population, popWeights)\n",
    "        # perform the crossover operation \n",
    "        crossedPair = crossover(selectionPair)\n",
    "        # mutation stage and not 'mutated' because mutation occurs at random rates\n",
    "        mutationStagePair = mutation(crossedPair, mutationRate=0.4)\n",
    "        # replace the population with new offsprings at the corresponding indexes\n",
    "        population = replacePopulation(population, popWeights, mutationStagePair)\n",
    "        # get the new fitness per route in the population index\n",
    "        popWeights = fitness(population, edges)[1]\n",
    "        # filter populations to preserve '50%' of the fittest routes in the current population for next iteration\n",
    "        nextPopulation = retainBestRoutes(population, popWeights)\n",
    "        print(f'nextPopulation: {nextPopulation}')\n",
    "\n",
    "        # iteration increment\n",
    "        iteration += 1\n",
    "    \n",
    "    # reset popWeights after loop to eval. new pop\n",
    "    popWeights = fitness(population, edges)[1]\n",
    "\n",
    "    # gets the shortest route found and the route distance\n",
    "    bestRoute = getBestRoute(population, popWeights)\n",
    "\n",
    "    # return the bestRoute along with route distance (tuple)\n",
    "    return bestRoute\n",
    "\n",
    "\n",
    "# dummy prints: for example purpose\n",
    "# store the results of runGeneticAlgorithm() in getRoute (iteration set to low number due to time constraints for developer's hardware specs.)\n",
    "getRoute = runGeneticAlgorithm(cluster=dummyCluster, size=4, iterationLimit=2, edges=edges)\n",
    "# get best route found by the G.A.\n",
    "bestRoute = getRoute[0]\n",
    "# get the distance of the best route\n",
    "routeDistance = getRoute[1]\n",
    "# display route and distance\n",
    "print(f'bestRoute: {bestRoute}\\n\\ndistance: {routeDistance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. FINDINGS AND COMPARISON OF GREEDY SEARCH APPROACH AND GENETIC ALGORITHM \n",
    "\n",
    "# Performance:\n",
    "(NB: the data below were collected from testing during code development)\n",
    "(NB: time to complete execution ('time taken') was retrieved from in-cell time tabs in jupyter notebook cells)\n",
    "(NB: since each task had different constriants, only comparable variables have been elected for this performance comparison)\n",
    "\n",
    "# Greedy Search\n",
    "- Distance converged: 20374.176350449245 \n",
    "- Path cost: 194640.17\n",
    "- Iterations taken: N/A (doesn't apply in this context)\n",
    "- Time taken: 9.4s\n",
    "\n",
    "# Genetic Algorithm \n",
    "- Distance converged: 47063.76523902698\n",
    "- Path cost: 633431.05 \n",
    "- Iterations taken: 2\n",
    "- Time taken: 3m 52.2s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant imports \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math \n",
    "\n",
    "gsDistance = 20374.176350449245\n",
    "gsPathCost = 194640.17\n",
    "\n",
    "gaDistance = 47063.76523902698\n",
    "gaPathCost = 633431.05 \n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "algorithms = ['Greedy Search', 'Genetic Algorithm']\n",
    "distance = [gsDistance, gaDistance]\n",
    "ax.bar(algorithms, distance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for each tasks are available on task1_solution.json and task2_solution.json respectively. (May need to execute the actual code files first for these outputs to be made)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- References: \n",
    "\n",
    "(1) https://peerj.com/articles/cs-55.pdf \n",
    "(2) https://data-flair.training/blogs/advantages-of-python-pandas/ \n",
    "(3) https://numpy.org/devdocs/user/absolute_beginners.html#:~:text=NumPy%20arrays%20are%20faster%20and,to%20be%20optimized%20even%20further. \n",
    "(4) https://www.javatpoint.com/pandas-vs-numpy \n",
    "(5) https://medium.com/fintechexplained/why-should-we-use-numpy-c14a4fb03ee9#:~:text=NumPy%20is%20an%20open%2Dsource,%2C%20statistical%2C%20and%20algebraic%20routines. \n",
    "(6) https://networkx.org/ \n",
    "(7) https://docs.scipy.org/doc/scipy/reference/spatial.distance.html \n",
    "(8) http://sbubeck.com/bubeck09a.pdf \n",
    "(9) https://www.geeksforgeeks.org/building-an-undirected-graph-and-finding-shortest-path-using-dictionaries-in-python/ \n",
    "(10) https://www.techopedia.com/definition/16931/greedy-algorithm \n",
    "[11] D. M. Chickering, Optimal Strucure Identification With Greedy Search, journal of machine learning research 3 (2002). [online] pp. 507-544\n",
    "[12] https://link.springer.com/chapter/10.1007/0-387-28356-0_4  \n",
    "[13] https://www.sciencedirect.com/topics/computer-science/wheel-selection#:~:text=The%20roulette%20wheel%20selection%20method,total%20fitness)%20of%20each%20individual. \n",
    "[14] https://mathworld.wolfram.com/LocalMinimum.html#:~:text=A%20local%20minimum%2C%20also%20called,may%20be)%20a%20global%20minimum. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7370fec6be111b608cc34d50d3192bee79c029552a2dcb4c2363d9b827a0176"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
